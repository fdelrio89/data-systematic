{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1885cded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import comet_ml\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from config import Config, load_config\n",
    "from data import CLEVRSplit, CLEVRTextSplit\n",
    "from model import Model, TextualModel, TrainingModel\n",
    "\n",
    "\n",
    "import lightning as L\n",
    "from lightning import Trainer\n",
    "from lightning.pytorch.loggers.comet import CometLogger\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "def log_to_comet():\n",
    "    return False\n",
    "#     return ('COMET_API_KEY' in os.environ and\n",
    "#             'COMET_WORKSPACE' in os.environ and\n",
    "#             'COMET_EXPERIMENT_KEY' in os.environ)\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "experiment_name = 'default-txt-scene--obj-desc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d67eb051",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_best_checkpoint_config(experiment_name):\n",
    "    all_checkpoints = Path(f\"outputs/{experiment_name}/\").glob('*.ckpt')\n",
    "    best_checkpoint = [p for p in all_checkpoints if 'last.ckpt' not in p.name][0]\n",
    "    ckpt = torch.load(best_checkpoint)\n",
    "    config = ckpt['hyper_parameters']['config']\n",
    "    return config, str(best_checkpoint)\n",
    "\n",
    "# config = Config()\n",
    "# config = load_config()\n",
    "config, checkpoint_path = load_best_checkpoint_config(experiment_name)\n",
    "\n",
    "# config.resume_training = True\n",
    "# config.rels_to_sample = 0\n",
    "# config.use_txt_scene = True\n",
    "# config.display_object_properties = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d645848e",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_config = load_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02fe750f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('resume_training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e81b344e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad_idx                   is different in config:  0 vs 1\n",
      "n_tokens                  is different in config:  95 vs 117\n",
      "max_scene_size            is different in config:  259 vs 659\n",
      "optimizer not in config\n",
      "weight_decay not in config\n",
      "use_txt_scene             is different in config:  False vs True\n",
      "display_object_properties is different in config:  False vs True\n",
      "profile not in config\n"
     ]
    }
   ],
   "source": [
    "for dk, dv in vars(default_config).items():\n",
    "    if dk not in vars(config):\n",
    "        print(dk, 'not in config')\n",
    "        continue\n",
    "    if dv != vars(config)[dk]:\n",
    "        print(f'{dk:25.25s} is different in config:  {dv} vs {vars(config)[dk]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924d8557",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "424e9d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building vocabulary\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fd0cbe547c84330b723d1fcc2ac3ff0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/699960 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building answers index\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f029defcfa674d17944445b49eb10e56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/699960 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if config.use_txt_scene:\n",
    "    train_dataset, test_dataset, systematic_dataset = CLEVRTextSplit.build_splits(config)\n",
    "else:\n",
    "    train_dataset, test_dataset, systematic_dataset = CLEVRSplit.build_splits(config)\n",
    "\n",
    "config.pad_idx = train_dataset.pad_idx\n",
    "\n",
    "test_dataset.processor.remove_unneeded_relations = True\n",
    "systematic_dataset.processor.remove_unneeded_relations = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9df952ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "dlkwargs = {\n",
    "    'batch_size': config.batch_size,\n",
    "    'num_workers': int(os.environ.get(\"SLURM_JOB_CPUS_PER_NODE\", 4)),\n",
    "    'pin_memory': torch.cuda.is_available(),\n",
    "}\n",
    "\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, **dlkwargs)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, **dlkwargs)\n",
    "systematic_loader = DataLoader(systematic_dataset, shuffle=False, **dlkwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b16a03bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.randint(0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68f898a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.use_txt_scene:\n",
    "    model = TextualModel(config)\n",
    "else:\n",
    "    model = Model(config)\n",
    "training_model = TrainingModel(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08810a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_model = TrainingModel.load_from_checkpoint(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dffdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = f\"outputs/{experiment_name}/\"\n",
    "if not os.path.exists(checkpoint_path):\n",
    "    os.mkdir(checkpoint_path)\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=checkpoint_path, save_top_k=1, monitor=\"val_loss/dataloader_idx_0\", every_n_epochs=1, save_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b99c0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch import loggers as pl_loggers\n",
    "\n",
    "tb_logger = pl_loggers.TensorBoardLogger(save_dir=\"logs/\")\n",
    "\n",
    "trainer = Trainer(max_epochs=config.max_epochs, accelerator=\"gpu\", devices=1,\n",
    "                    logger=tb_logger, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ace5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(training_model, ckpt_path='last', dataloaders=[test_loader, systematic_loader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c63f2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05393d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_path = f\"outputs/{experiment_name}/\"\n",
    "# if not os.path.exists(checkpoint_path):\n",
    "#     os.mkdir(checkpoint_path)\n",
    "# checkpoint_callback = ModelCheckpoint(\n",
    "#     dirpath=checkpoint_path, save_top_k=1, monitor=\"val_loss/dataloader_idx_0\", every_n_epochs=1, save_last=True)\n",
    "\n",
    "# resume_from_path = None\n",
    "# if config.resume_training:\n",
    "#     resume_from_path = checkpoint_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a70c8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_obj_properties(start, program):\n",
    "#     next_ =  start['inputs'][0]\n",
    "# #     properties = {'material': None, 'color': None, 'shape': None, 'size': None}\n",
    "#     properties = {}\n",
    "    \n",
    "#     while program[next_]['function'] in {'filter_material', 'filter_color', 'filter_shape', 'filter_size'}:\n",
    "#         next_fn = program[next_]\n",
    "#         fn_type = next_fn['function']\n",
    "#         property_type = fn_type.replace('filter_', '')\n",
    "#         properties[property_type] = next_fn['value_inputs'][0]\n",
    "#         next_ = next_fn['inputs'][0]\n",
    "        \n",
    "#     return properties\n",
    "\n",
    "# def object_satisfy(object_, properties):\n",
    "#     for k, v in properties.items():\n",
    "#         if object_[k] != v:\n",
    "#             return False\n",
    "#     return True\n",
    "\n",
    "# def is_object_relevant(object_, all_properties):\n",
    "#     return any(object_satisfy(object_, properties) for properties in all_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec941075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # program = test_dataset.questions[1000]['program']\n",
    "# # scene = test_dataset.indexed_scenes[test_dataset.questions[1000]['image_index']]\n",
    "\n",
    "# prop = []\n",
    "# for q in test_dataset.questions:\n",
    "#     program = q['program']\n",
    "#     scene = test_dataset.indexed_scenes[q['image_index']]\n",
    "\n",
    "#     objects = scene['objects']\n",
    "\n",
    "#     start_nodes = [fn for fn in program if fn['function'] in {'count', 'exist', 'unique', 'union'}]\n",
    "# #     start_nodes = [fn for fn in program if fn['function'] in {'union' , 'unique'}]\n",
    "\n",
    "#     relevant_properties = []\n",
    "#     for obj_to_filter in start_nodes:\n",
    "#         relevant_properties.append(get_obj_properties(obj_to_filter, program))\n",
    "\n",
    "#     relevant_objects = [(o_idx, o) for o_idx, o in enumerate(objects) if is_object_relevant(o, relevant_properties)]\n",
    "\n",
    "#     prop.append(len(relevant_objects) / len(objects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405cb39d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# np.mean(prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916e0804",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# {fn['function'] for q in test_dataset.questions for fn in q['program']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfe133a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# qs = random.sample(test_dataset.questions, k=10)\n",
    "# for q in qs:\n",
    "#     print(q['question'], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850ec0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fn_types = list({fn['function'] for q in test_dataset.questions for fn in q['program']})\n",
    "\n",
    "# for fn_type in fn_types:\n",
    "\n",
    "#     count = 0\n",
    "#     for idx, q in enumerate(test_dataset.questions):\n",
    "#         for p in q['program']:\n",
    "#             if p['inputs']:\n",
    "#                 for input_ in p['inputs']:\n",
    "#                     if fn_type == p['function'] and 'filter_' in q['program'][input_]['function']:\n",
    "#                         count += 1\n",
    "# #                         print(idx)\n",
    "                \n",
    "#     if count > 0:\n",
    "#         print(fn_type) \n",
    "\n",
    "# count = 0\n",
    "# for idx, q in enumerate(test_dataset.questions):\n",
    "#     for p in q['program']:\n",
    "#         if p['inputs']:\n",
    "#             input_ = p['inputs'][0]\n",
    "#         if 'relate' == p['function'] and q['program'][input_]['function'] != 'unique':\n",
    "#             print(idx)\n",
    "#             continue\n",
    "#         else:\n",
    "#             count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809a80c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# q = qs[9]\n",
    "\n",
    "# program = q['program']\n",
    "# scene = test_dataset.indexed_scenes[q['image_index']]\n",
    "\n",
    "# objects = scene['objects']\n",
    "\n",
    "# start_nodes = [fn for fn in program if fn['function'] in {'unique', 'count'}]\n",
    "\n",
    "# relevant_properties = []\n",
    "# for obj_to_filter in start_nodes:\n",
    "#     relevant_properties.append(get_obj_properties(obj_to_filter, program))\n",
    "\n",
    "# relevant_objects = [(o_idx, o) for o_idx, o in enumerate(objects) if is_object_relevant(o, relevant_properties)]\n",
    "\n",
    "# print(q['question'], '\\n')\n",
    "\n",
    "# for idx, p in enumerate(program):\n",
    "#     print(idx, ':', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7041d90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad_used = []\n",
    "# total_seqs = []\n",
    "# for scenes, questions, answers in test_loader:\n",
    "#     pad_used.append((scenes == config.pad_idx).sum())\n",
    "#     total_seqs.append(scenes.numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904f4b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import Scene\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "remove_unneeded_relations = False\n",
    "\n",
    "scene_lengths = []\n",
    "# for question in test_dataset.questions:\n",
    "\n",
    "question = test_dataset.questions[2893]\n",
    "\n",
    "image_idx = question['image_index']\n",
    "scene = test_dataset.indexed_scenes[image_idx]\n",
    "\n",
    "question_str = question['question']\n",
    "answer_str = question['answer']\n",
    "\n",
    "filter_objects_from_relations = None\n",
    "if remove_unneeded_relations:\n",
    "    filter_objects_from_relations = test_dataset.processor.get_objects_to_filter(question, scene)\n",
    "\n",
    "# scene_str = self.scene_to_txt(scene, rels_to_sample=self.rels_to_sample)\n",
    "scene_object = Scene.from_dict(scene,\n",
    "                            shuffle_relations=True,\n",
    "                            relations_to_sample=0,\n",
    "                            only_front_right=config.only_front_right_relations,\n",
    "                            filter_symmetric=config.filter_symmetric_relations,\n",
    "                            always_display_properties=config.display_object_properties,\n",
    "                            filter_objects_from_relations=filter_objects_from_relations)\n",
    "scene_str = str(scene_object)\n",
    "\n",
    "tokenized_scene = test_dataset.processor.tokenize_sequence(\n",
    "    scene_str, test_dataset.processor.max_scene_size, pad_seq=False, lower=False)\n",
    "\n",
    "scene_lengths.append(len(tokenized_scene))\n",
    "\n",
    "# plt.hist(scene_lengths, bins=50)\n",
    "# plt.plot()\n",
    "\n",
    "# print((np.array(scene_lengths) > 259).sum() / len(scene_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79950995",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e1ee40",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_object.relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf32602",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3353b1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_object.relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a968c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98faf853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question_index': 2893,\n",
       " 'question_family_index': 19,\n",
       " 'image_index': 289,\n",
       " 'question': 'Is the material of the small yellow block that is to the left of the cyan metallic cylinder the same as the tiny ball?',\n",
       " 'answer': 'no',\n",
       " 'image_filename': 'CLEVR_valA_000289.png',\n",
       " 'split': 'valA',\n",
       " 'program': [{'value_inputs': [], 'inputs': [], 'function': 'scene'},\n",
       "  {'value_inputs': ['cyan'], 'inputs': [0], 'function': 'filter_color'},\n",
       "  {'value_inputs': ['metal'], 'inputs': [1], 'function': 'filter_material'},\n",
       "  {'value_inputs': ['cylinder'], 'inputs': [2], 'function': 'filter_shape'},\n",
       "  {'value_inputs': [], 'inputs': [3], 'function': 'unique'},\n",
       "  {'value_inputs': ['left'], 'inputs': [4], 'function': 'relate'},\n",
       "  {'value_inputs': ['small'], 'inputs': [5], 'function': 'filter_size'},\n",
       "  {'value_inputs': ['yellow'], 'inputs': [6], 'function': 'filter_color'},\n",
       "  {'value_inputs': ['cube'], 'inputs': [7], 'function': 'filter_shape'},\n",
       "  {'value_inputs': [], 'inputs': [8], 'function': 'unique'},\n",
       "  {'value_inputs': [], 'inputs': [9], 'function': 'query_material'},\n",
       "  {'value_inputs': [], 'inputs': [], 'function': 'scene'},\n",
       "  {'value_inputs': ['small'], 'inputs': [11], 'function': 'filter_size'},\n",
       "  {'value_inputs': ['sphere'], 'inputs': [12], 'function': 'filter_shape'},\n",
       "  {'value_inputs': [], 'inputs': [13], 'function': 'unique'},\n",
       "  {'value_inputs': [], 'inputs': [14], 'function': 'query_material'},\n",
       "  {'value_inputs': [], 'inputs': [10, 15], 'function': 'equal_material'}]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.questions[2893]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944b4a77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
