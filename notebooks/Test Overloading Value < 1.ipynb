{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc18d515",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import random\n",
    "import pprint\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "\n",
    "from config import load_config\n",
    "from data import (build_datasets,\n",
    "                  CollatorForMaskedLanguageModeling,\n",
    "                  CollatorForMaskedSelectedTokens,\n",
    "                  CollatorForMaskedRandomSelectedTokens,\n",
    "                  IdentityCollator)\n",
    "from data import ALL_POSSIBLE_COLORS\n",
    "from model import MultimodalModel, MultimodalPretrainingModel\n",
    "from lightning import Trainer, seed_everything\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0608ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a64e591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 999\n"
     ]
    }
   ],
   "source": [
    "exp_name = 'mmlm--n_colors=8c--mlm_probability=0.15' \n",
    "\n",
    "to_clean_int = lambda str_: ''.join(filter(str.isdigit, str_))\n",
    "get_version = lambda p: int(to_clean_int(p.stem)) if to_clean_int(p.stem) else 0\n",
    "\n",
    "checkpoint_paths = sorted(Path(f'outputs/{exp_name}/').glob('last*.ckpt'), key=get_version, reverse=True)\n",
    "resume_from_path = str(checkpoint_paths[0])\n",
    "checkpoint = torch.load(resume_from_path)\n",
    "\n",
    "print('Epoch:', checkpoint['epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d1336bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading mmlm--n_colors=8c--mlm_probability=0.15 last checkpoint config from outputs/mmlm--n_colors=8c--mlm_probability=0.15/last.ckpt\n",
      "Add new arg: aug_zero_color = False\n"
     ]
    }
   ],
   "source": [
    "config = load_config(exp_name)\n",
    "\n",
    "config.vocabulary_path = config.vocabulary_path.replace('/workspace/' ,'/workspace1/')\n",
    "config.base_path = config.base_path.replace('/workspace/' ,'/workspace1/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23aded44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d46a7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.aug_zero = 4\n",
    "config.aug_zero_independent = True\n",
    "config.aug_zero_color = True\n",
    "\n",
    "config.shuffle_object_identities = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa0d08d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e653b46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset, systematic_dataset, common_systematic_dataset = build_datasets(config)\n",
    "config.pad_idx = train_dataset.pad_idx\n",
    "processor = test_dataset.processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcba0aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06c8fe3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fidelrio/.pyenv/versions/systematicity/lib/python3.7/site-packages/lightning/pytorch/utilities/parsing.py:270: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "  f\"Attribute {k!r} is an instance of `nn.Module` and is already saved during checkpointing.\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultimodalModel(config)\n",
    "training_model = MultimodalPretrainingModel(model, config)\n",
    "training_model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1adc0a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa7f06bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_tokens = sorted([processor.vocabulary[w] for w in ['left', 'right', 'behind', 'front']])\n",
    "color_tokens = sorted(\n",
    "    set([processor.vocabulary[w] for w in ALL_POSSIBLE_COLORS if w in processor.vocabulary]))\n",
    "shapes_tokens = sorted([processor.vocabulary[w] for w in ['cylinder', 'sphere', 'cube']])\n",
    "materials_tokens = sorted([processor.vocabulary[w] for w in ['metal', 'rubber']])\n",
    "size_tokens = sorted([processor.vocabulary[w] for w in ['small', 'large']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "884e2101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collator = CollatorForMaskedLanguageModeling(config, processor)\n",
    "collator = IdentityCollator(config, processor)\n",
    "train_loader = DataLoader(train_dataset, shuffle=False, collate_fn=collator, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4a3e09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa55235b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 96)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.n_tokens, len(processor.vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a80934",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cbf92ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_idx(idx):\n",
    "    vocab_size = len(processor.vocabulary)\n",
    "    n_colors = len(color_tokens)\n",
    "    min_color_idx = min(color_tokens)\n",
    "    vocab_idx = (idx - vocab_size) // n_colors\n",
    "    \n",
    "    if idx < vocab_size:\n",
    "        return idx\n",
    "    return idx - vocab_size + min_color_idx - vocab_idx*n_colors\n",
    "\n",
    "def scene_tensor_to_txt(tensor):\n",
    "    return ' '.join([processor.inv_vocabulary.get(translate_idx(t), str(t)) for t in tensor.tolist()])\n",
    "\n",
    "def print_scene_tensor(tensor):\n",
    "    scene_text = scene_tensor_to_txt(tensor)\n",
    "    print(scene_text.replace('[PAD]', '').replace('[SEP]','\\n     '))\n",
    "    \n",
    "def print_parallel(tensor0, tensor1, tensor2, confidences, titles):\n",
    "    ttl0, ttl1, ttl2 = titles\n",
    "    print(f'{ttl0:6.6s} {ttl1:6.6s} {ttl2:6.6s}')\n",
    "    for t0, t1, t2, conf in zip(\n",
    "            tensor0.tolist(), tensor1.tolist(), tensor2.tolist(), confidences.tolist()):\n",
    "        w0 = processor.inv_vocabulary[t0]\n",
    "        w1 = processor.inv_vocabulary[t1]\n",
    "        w2 = processor.inv_vocabulary[t2]\n",
    "        \n",
    "        if w0 == '[SEP]':\n",
    "            print()\n",
    "            continue\n",
    "        if w0 == '[PAD]':\n",
    "            break\n",
    "        \n",
    "        print_txt = f'{w0:6.6s} {w1:6.6s} {w2:6.6s} ({conf:.4f})'\n",
    "        if w0 != w2:\n",
    "            print_txt = bold(print_txt)\n",
    "            \n",
    "\n",
    "        print(print_txt)\n",
    "        \n",
    "def bold(text):\n",
    "    return (\"\\033[1m\" + text + \"\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "479a4f45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-f3c84cc3232e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0ms2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscene_tensor_to_txt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscene2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0ms1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0ms2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscene1\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mscene2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for _ in range(2000):\n",
    "    b = next(iter(train_loader))\n",
    "    scene1 = b[1]\n",
    "    scene.max(), scene[:,:]\n",
    "\n",
    "    s1 = scene_tensor_to_txt(scene1[0])\n",
    "\n",
    "    b = next(iter(train_loader))\n",
    "    scene2 = b[1]\n",
    "    scene.max(), scene[:,:]\n",
    "\n",
    "    s2 = scene_tensor_to_txt(scene2[0]) \n",
    "    assert (scene1 != scene2).any() # If fails should be here\n",
    "    assert s1 == s2                 # Never here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862a4b84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea29178b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1dc2a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f51c726",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d914cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f459592e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df134d07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119643b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbc14da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4c57d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
