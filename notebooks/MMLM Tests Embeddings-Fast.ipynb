{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc18d515",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/mnt/ialabnas/homes/fidelrio/systematic-text-representations/')\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "import random\n",
    "import pprint\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "from config import load_config\n",
    "from data import build_datasets, build_loader, build_detailed_test_dataloaders\n",
    "from data import CollatorForMaskedSelectedTokens, CollatorForMaskedRandomSelectedTokens, IdentityCollator\n",
    "from data import ALL_POSSIBLE_COLORS\n",
    "from model import MultimodalModel, MultimodalPretrainingModel\n",
    "from utils import load_checkpoint\n",
    "from lightning import Trainer, seed_everything\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e164864d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0608ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07b47f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scene_tensor_to_txt(tensor):\n",
    "    return ' '.join([processor.inv_vocabulary[t] for t in tensor.tolist()])\n",
    "\n",
    "def print_scene_tensor(tensor):\n",
    "    scene_text = scene_tensor_to_txt(tensor)\n",
    "    print(scene_text.replace('[PAD]', '').replace('[SEP]','\\n     '))\n",
    "    \n",
    "def print_parallel(tensor0, tensor1, tensor2, confidences, titles):\n",
    "    ttl0, ttl1, ttl2 = titles\n",
    "    print(f'{ttl0:6.6s} {ttl1:6.6s} {ttl2:6.6s}')\n",
    "    for t0, t1, t2, conf in zip(\n",
    "            tensor0.tolist(), tensor1.tolist(), tensor2.tolist(), confidences.tolist()):\n",
    "        w0 = processor.inv_vocabulary[t0]\n",
    "        w1 = processor.inv_vocabulary[t1]\n",
    "        w2 = processor.inv_vocabulary[t2]\n",
    "        \n",
    "        if w0 == '[SEP]':\n",
    "            print()\n",
    "            continue\n",
    "        if w0 == '[PAD]':\n",
    "            break\n",
    "        \n",
    "        print_txt = f'{w0:6.6s} {w1:6.6s} {w2:6.6s} ({conf:.4f})'\n",
    "        if w0 != w2:\n",
    "            print_txt = bold(print_txt)\n",
    "            \n",
    "\n",
    "        print(print_txt)\n",
    "        \n",
    "def bold(text):\n",
    "    return (\"\\033[1m\" + text + \"\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbbf4a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a64e591",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 999\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "\n",
    "n_colors = 8\n",
    "epoch = None\n",
    "exp_name = f'mmlm--n_colors={n_colors}c--mlm_probability=0.15'\n",
    "\n",
    "checkpoint = load_checkpoint(exp_name, epoch=epoch)\n",
    "print('Epoch:', checkpoint['epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77671ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e92f3603",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'epoch=109-step=16170.ckpt'  'epoch=579-step=85260.ckpt'\r\n",
      "'epoch=119-step=17640.ckpt'  'epoch=589-step=86730.ckpt'\r\n",
      "'epoch=129-step=19110.ckpt'  'epoch=599-step=88200.ckpt'\r\n",
      "'epoch=139-step=20580.ckpt'  'epoch=59-step=8820.ckpt'\r\n",
      "'epoch=149-step=22050.ckpt'  'epoch=609-step=89670.ckpt'\r\n",
      "'epoch=159-step=23520.ckpt'  'epoch=619-step=91140.ckpt'\r\n",
      "'epoch=169-step=24990.ckpt'  'epoch=629-step=92610.ckpt'\r\n",
      "'epoch=179-step=26460.ckpt'  'epoch=639-step=94080.ckpt'\r\n",
      "'epoch=189-step=27930.ckpt'  'epoch=649-step=95550.ckpt'\r\n",
      "'epoch=199-step=29400.ckpt'  'epoch=659-step=97020.ckpt'\r\n",
      "'epoch=19-step=2940.ckpt'    'epoch=669-step=98490.ckpt'\r\n",
      "'epoch=209-step=30870.ckpt'  'epoch=679-step=99960.ckpt'\r\n",
      "'epoch=219-step=32340.ckpt'  'epoch=689-step=101430.ckpt'\r\n",
      "'epoch=229-step=33810.ckpt'  'epoch=699-step=102900.ckpt'\r\n",
      "'epoch=239-step=35280.ckpt'  'epoch=69-step=10290.ckpt'\r\n",
      "'epoch=249-step=36750.ckpt'  'epoch=709-step=104370.ckpt'\r\n",
      "'epoch=259-step=38220.ckpt'  'epoch=719-step=105840.ckpt'\r\n",
      "'epoch=269-step=39690.ckpt'  'epoch=729-step=107310.ckpt'\r\n",
      "'epoch=279-step=41160.ckpt'  'epoch=739-step=108780.ckpt'\r\n",
      "'epoch=289-step=42630.ckpt'  'epoch=749-step=110250.ckpt'\r\n",
      "'epoch=299-step=44100.ckpt'  'epoch=759-step=111720.ckpt'\r\n",
      "'epoch=29-step=4410.ckpt'    'epoch=769-step=113190.ckpt'\r\n",
      "'epoch=309-step=45570.ckpt'  'epoch=779-step=114660.ckpt'\r\n",
      "'epoch=319-step=47040.ckpt'  'epoch=789-step=116130.ckpt'\r\n",
      "'epoch=329-step=48510.ckpt'  'epoch=799-step=117600.ckpt'\r\n",
      "'epoch=339-step=49980.ckpt'  'epoch=79-step=11760.ckpt'\r\n",
      "'epoch=349-step=51450.ckpt'  'epoch=809-step=119070.ckpt'\r\n",
      "'epoch=359-step=52920.ckpt'  'epoch=819-step=120540.ckpt'\r\n",
      "'epoch=369-step=54390.ckpt'  'epoch=829-step=122010.ckpt'\r\n",
      "'epoch=379-step=55860.ckpt'  'epoch=839-step=123480.ckpt'\r\n",
      "'epoch=389-step=57330.ckpt'  'epoch=849-step=124950.ckpt'\r\n",
      "'epoch=399-step=58800.ckpt'  'epoch=859-step=126420.ckpt'\r\n",
      "'epoch=39-step=5880.ckpt'    'epoch=869-step=127890.ckpt'\r\n",
      "'epoch=409-step=60270.ckpt'  'epoch=879-step=129360.ckpt'\r\n",
      "'epoch=419-step=61740.ckpt'  'epoch=889-step=130830.ckpt'\r\n",
      "'epoch=429-step=63210.ckpt'  'epoch=899-step=132300.ckpt'\r\n",
      "'epoch=439-step=64680.ckpt'  'epoch=89-step=13230.ckpt'\r\n",
      "'epoch=449-step=66150.ckpt'  'epoch=909-step=133770.ckpt'\r\n",
      "'epoch=459-step=67620.ckpt'  'epoch=919-step=135240.ckpt'\r\n",
      "'epoch=469-step=69090.ckpt'  'epoch=929-step=136710.ckpt'\r\n",
      "'epoch=479-step=70560.ckpt'  'epoch=939-step=138180.ckpt'\r\n",
      "'epoch=489-step=72030.ckpt'  'epoch=949-step=139650.ckpt'\r\n",
      "'epoch=499-step=73500.ckpt'  'epoch=959-step=141120.ckpt'\r\n",
      "'epoch=49-step=7350.ckpt'    'epoch=969-step=142590.ckpt'\r\n",
      "'epoch=509-step=74970.ckpt'  'epoch=979-step=144060.ckpt'\r\n",
      "'epoch=519-step=76440.ckpt'  'epoch=989-step=145530.ckpt'\r\n",
      "'epoch=529-step=77910.ckpt'  'epoch=999-step=147000.ckpt'\r\n",
      "'epoch=539-step=79380.ckpt'  'epoch=99-step=14700.ckpt'\r\n",
      "'epoch=549-step=80850.ckpt'  'epoch=9-step=1470.ckpt'\r\n",
      "'epoch=559-step=82320.ckpt'   last.ckpt\r\n",
      "'epoch=569-step=83790.ckpt'\r\n"
     ]
    }
   ],
   "source": [
    "!ls outputs/$exp_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d1336bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading mmlm--n_colors=8c--mlm_probability=0.15 last checkpoint config from outputs/mmlm--n_colors=8c--mlm_probability=0.15/last.ckpt\n",
      "Add new arg: aug_zero_color = False\n"
     ]
    }
   ],
   "source": [
    "config = load_config(exp_name)\n",
    "\n",
    "config.vocabulary_path = config.vocabulary_path.replace('/workspace/' ,'/workspace1/')\n",
    "config.base_path = config.base_path.replace('/workspace/' ,'/workspace1/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "671ee85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pp.pprint(vars(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e653b46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset, systematic_dataset, common_systematic_dataset = build_datasets(config)\n",
    "config.pad_idx = train_dataset.pad_idx\n",
    "config.n_tokens = train_dataset.n_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab071f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loaders = build_detailed_test_dataloaders(test_dataset, config) # type_of_tokens_to_test\n",
    "systematic_loaders = build_detailed_test_dataloaders(systematic_dataset, config) # type_of_tokens_to_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06c8fe3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fidelrio/.pyenv/versions/systematicity/lib/python3.7/site-packages/lightning/pytorch/utilities/parsing.py:270: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "  f\"Attribute {k!r} is an instance of `nn.Module` and is already saved during checkpointing.\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultimodalModel(config).to(device)\n",
    "training_model = MultimodalPretrainingModel(model, config).to(device)\n",
    "training_model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ba4dfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a26f537b",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = test_dataset.processor\n",
    "mask_token_idx = processor.vocabulary['[MASK]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f49541a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomPixelShuffle(object):\n",
    "    def __call__(self, img):\n",
    "        channels, height, width = img.size()\n",
    "        indices = np.random.permutation(height * width)\n",
    "        shuffled_img = img.view(channels, -1)[:, indices].view(channels, height, width)\n",
    "        return shuffled_img\n",
    "\n",
    "from torchvision import transforms\n",
    "try:\n",
    "    original_transform\n",
    "except NameError:\n",
    "    original_transform = processor.image_transform\n",
    "\n",
    "processor.image_transform = transforms.Compose([\n",
    "    original_transform,\n",
    "    RandomPixelShuffle()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa7f06bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_tokens = sorted([processor.vocabulary[w] for w in ['left', 'right', 'behind', 'front']])\n",
    "color_tokens = sorted(\n",
    "    [processor.vocabulary[w] for w in ALL_POSSIBLE_COLORS if w in processor.vocabulary])\n",
    "shapes_tokens = sorted([processor.vocabulary[w] for w in ['cylinder', 'sphere', 'cube']])\n",
    "materials_tokens = sorted([processor.vocabulary[w] for w in ['metal', 'rubber']])\n",
    "size_tokens = sorted([processor.vocabulary[w] for w in ['small', 'large']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ca80e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "884e2101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collator = CollatorForMaskedLanguageModeling(config, processor)\n",
    "collator = CollatorForMaskedSelectedTokens(config, processor, tokens=color_tokens)\n",
    "# collator = CollatorForMaskedRandomSelectedTokens(config, processor, tokens=shapes_tokens, p=0.2)\n",
    "# collator = IdentityCollator(config, processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ddee22b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13979\n"
     ]
    }
   ],
   "source": [
    "# sample_idx = 333\n",
    "sample_idx = random.randint(0, len(test_dataset))\n",
    "image, scene = test_dataset.retrieve_raw(sample_idx)\n",
    "image_tensor, scene_tensor = test_dataset[sample_idx]\n",
    "\n",
    "collated_images, collated_scenes, collated_labels = collator([(image_tensor, scene_tensor)])\n",
    "collated_images = collated_images.to(device)\n",
    "collated_scenes = collated_scenes.to(device)\n",
    "collated_labels = collated_labels.to(device)\n",
    "\n",
    "print(sample_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0cc27064",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_logits = model(collated_images, collated_scenes)\n",
    "\n",
    "confidences = softmax(output_logits, dim=-1).max(dim=-1).values\n",
    "predictions = output_logits.argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1632e2b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08be2d2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca97753c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(max_epochs=config.max_epochs,\n",
    "                  accelerator=\"gpu\",\n",
    "                  devices=torch.cuda.device_count()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d24c802b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = processor.vocabulary\n",
    "\n",
    "relation_tokens = sorted(\n",
    "    [vocab[w] for w in ['left', 'right', 'behind', 'front'] if w in vocab])\n",
    "colors_tokens = sorted(\n",
    "    [vocab[w] for w in ALL_POSSIBLE_COLORS if w in vocab])\n",
    "#     [vocab[w] for w in ['blue', 'brown', 'cyan', 'green', 'red', 'purple', 'yellow', 'gray']])\n",
    "shapes_tokens = sorted(\n",
    "    [vocab[w] for w in ['cylinder', 'sphere', 'cube'] if w in vocab])\n",
    "materials_tokens = sorted(\n",
    "    [vocab[w] for w in ['metal', 'rubber'] if w in vocab])\n",
    "sizes_tokens = sorted(\n",
    "    [vocab[w] for w in ['small', 'large'] if w in vocab])\n",
    "\n",
    "random_baseline = {\n",
    "    'relation':  1 / len(relation_tokens),\n",
    "    'color':  1 / len(color_tokens),\n",
    "    'shapes':  1 / len(shapes_tokens),\n",
    "    'materials':  1 / len(materials_tokens),\n",
    "    'size':  1 / len(size_tokens),\n",
    "    'identity':  1 / len(processor.vocabulary),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7d310a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8316f4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "test_indices = random.sample(range(len(test_dataset)), k=batch_size)\n",
    "pc_subset_test = Subset(test_dataset, test_indices)\n",
    "pc_subset_systematic = Subset(systematic_dataset, test_indices)\n",
    "\n",
    "colors_collator = CollatorForMaskedSelectedTokens(config, processor, tokens=colors_tokens)\n",
    "shapes_collator = CollatorForMaskedSelectedTokens(config, processor, tokens=shapes_tokens)\n",
    "materials_collator = CollatorForMaskedSelectedTokens(config, processor, tokens=materials_tokens)\n",
    "sizes_collator = CollatorForMaskedSelectedTokens(config, processor, tokens=sizes_tokens)\n",
    "dlkwargs = {\n",
    "    'batch_size': batch_size,\n",
    "    'num_workers': int(os.environ.get(\"SLURM_CPUS_PER_TASK\", 4)),\n",
    "    'pin_memory': torch.cuda.is_available(),\n",
    "}\n",
    "\n",
    "for task, collator in [('colors', colors_collator),\n",
    "                       ('shapes', shapes_collator),\n",
    "                       ('materials', materials_collator),\n",
    "                       ('sizes', sizes_collator)]:\n",
    "    \n",
    "    test_loaders[task] = DataLoader(\n",
    "        pc_subset_test, shuffle=False, collate_fn=collator, **dlkwargs)\n",
    "    systematic_loaders[task] = DataLoader(\n",
    "        pc_subset_systematic, shuffle=False, collate_fn=collator, **dlkwargs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2255ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5593821b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14f5dc6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x7f8dad491b10>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_maps = []  # This will be a list of Tensors, each representing a feature map\n",
    "\n",
    "def hook_feat_map(mod, inp, out):\n",
    "    feature_maps.clear()\n",
    "    feature_maps.append(out)\n",
    "\n",
    "model.transformer.register_forward_hook(hook_feat_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99105f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd6a332e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images.shape, scenes.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "027ae3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tasks = ['colors', 'shapes', 'materials', 'sizes']\n",
    "tasks = ['shapes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da467a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_by_set = {}\n",
    "gt_by_set = {}\n",
    "for test_name, loaders in [('test', test_loaders), ('systematic', systematic_loaders)]:\n",
    "    feats_by_task = {}\n",
    "    gt_by_task = {}\n",
    "    for task in tasks:\n",
    "        images, scenes, labels = next(iter(loaders[task]))\n",
    "        images, scenes, labels = images.to(device), scenes.to(device), labels.to(device)\n",
    "        cimages, cscenes, clabels = images, scenes, labels\n",
    "        with torch.no_grad():\n",
    "            output_logits = model(images, scenes)\n",
    "\n",
    "            features = feature_maps[0]\n",
    "            confidences = softmax(output_logits, dim=-1).max(dim=-1).values\n",
    "            predictions = output_logits.argmax(dim=-1)\n",
    "\n",
    "            scene_features = features.transpose(1,0)[:,-config.max_scene_size:]\n",
    "            mask_idxs = (scenes == mask_token_idx)\n",
    "            gt_by_task[task] = labels[:,-config.max_scene_size:][mask_idxs].cpu()\n",
    "            feats_by_task[task] = scene_features[mask_idxs].cpu()\n",
    "            \n",
    "    feats_by_set[test_name] = feats_by_task\n",
    "    gt_by_set[test_name] = gt_by_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0eaf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_idxs = torch.unique(torch.cat([gt_by_set['test'][t] for t in tasks]))\n",
    "clf_idxs_by_task = {t: torch.unique(gt_by_set['test'][t]) for t in tasks}\n",
    "all_clf_vectors = model.classifier.weight.data.cpu()\n",
    "clf_vectors = model.classifier.weight.data.cpu()[clf_idxs]\n",
    "clf_vectors_by_task = {t: all_clf_vectors[tidxs] for t, tidxs in clf_idxs_by_task.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92e6b6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b65ed89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_pca(X,\n",
    "                y, \n",
    "                title='', \n",
    "                special_X=None, \n",
    "                special_y=None, \n",
    "                don_t_label_these=[], \n",
    "                labels_to_use=[], \n",
    "                special_labels_to_use=[], \n",
    "                ax=None):\n",
    "\n",
    "    is_3d = X.shape[-1] == 3\n",
    "\n",
    "    if ax is None:\n",
    "        fig = plt.figure(figsize=(9*1.75,5*1.75))\n",
    "        if is_3d:\n",
    "            ax = fig.add_subplot(projection='3d')\n",
    "        else:\n",
    "            ax = fig.add_subplot()\n",
    "\n",
    "    label_namer = processor.inv_vocabulary\n",
    "    if labels_to_use:\n",
    "        label_namer = labels_to_use\n",
    "    for label_idx in sorted(set(y)):\n",
    "        idxs = y == label_idx \n",
    "        label = label_namer[label_idx]\n",
    "\n",
    "        plot_args = [X[:,0][idxs], X[:,1][idxs]]\n",
    "        if is_3d:\n",
    "            plot_args = plot_args + [X[:,2][idxs]]\n",
    "\n",
    "        plot_kwargs = {}\n",
    "        if not don_t_label_these or label not in don_t_label_these:\n",
    "            plot_kwargs['label'] = label\n",
    "\n",
    "        scatter_shapes = ax.scatter(*plot_args, **plot_kwargs)\n",
    "       \n",
    "    special_label_namer = processor.inv_vocabulary\n",
    "    if labels_to_use:\n",
    "        special_label_namer = labels_to_use\n",
    "    if special_labels_to_use:\n",
    "        special_label_namer = special_labels_to_use\n",
    "    if special_X is not None:\n",
    "        for label_idx in sorted(set(special_y)): \n",
    "            label = special_label_namer[label_idx]\n",
    "\n",
    "            plot_kwargs = {}\n",
    "            if not don_t_label_these or label not in don_t_label_these:\n",
    "                plot_kwargs['label'] = label\n",
    "\n",
    "            special_idxs = special_y == label_idx \n",
    "            special_plot_args = [special_X[:,0][special_idxs], special_X[:,1][special_idxs]]\n",
    "            if is_3d:\n",
    "                special_plot_args = special_plot_args + [special_X[:,2][special_idxs]]\n",
    "\n",
    "#             color = scatter_shapes.get_facecolors()[0]\n",
    "#             plot_kwargs['color'] = color\n",
    "            plot_kwargs['marker'] = '*'\n",
    "            if not is_3d:\n",
    "                plot_kwargs['s'] = 200\n",
    "        \n",
    "            ax.scatter(*special_plot_args, **plot_kwargs)\n",
    "\n",
    "\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "    ax.legend(framealpha=1, loc='upper left')\n",
    "\n",
    "    # Show plot\n",
    "    # plt.savefig('exports/base-attributes.pdf', format='pdf', dpi=300, bbox_inches='tight')\n",
    "    if not ax:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd2ccff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2cc396",
   "metadata": {},
   "outputs": [],
   "source": [
    "don_t_label_these = [] if n_colors <= 27 else ALL_POSSIBLE_COLORS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f468366",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f6a9c78",
   "metadata": {},
   "source": [
    "### Shape Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0946d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d7ad19",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_X = torch.cat([clf_vectors_by_task[t] for t in ['shapes']]).numpy()\n",
    "special_gts = torch.cat([clf_idxs_by_task[t] for t in ['shapes']]).numpy()\n",
    "\n",
    "\n",
    "# special_X = torch.cat([clf_vectors_by_task[t] for t in tasks]).numpy()\n",
    "# special_gts = torch.cat([clf_idxs_by_task[t] for t in tasks]).numpy()\n",
    "# X_2d_clf = pca.transform(special_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fae608",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(1.5*9*1.75,5*1.75))\n",
    "\n",
    "X = feats_by_set['test']['shapes'].numpy()\n",
    "all_gts = gt_by_set['test']['shapes'].numpy()\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_2d = pca.fit_transform(X)\n",
    "\n",
    "\n",
    "scatter_pca(\n",
    "    X_2d, \n",
    "    all_gts, \n",
    "    special_X=pca.transform(special_X),\n",
    "    special_y=special_gts,\n",
    "    don_t_label_these=[], \n",
    "    title='IID Test', \n",
    "    ax=axs[0])\n",
    "\n",
    "\n",
    "X = feats_by_set['systematic']['shapes'].numpy()\n",
    "all_gts = gt_by_set['systematic']['shapes'].numpy()\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_2d = pca.fit_transform(X)\n",
    "\n",
    "scatter_pca(\n",
    "    X_2d, \n",
    "    all_gts, \n",
    "    special_X=pca.transform(special_X),\n",
    "    special_y=special_gts,\n",
    "    don_t_label_these=[], \n",
    "    title='Systematic Test', \n",
    "    ax=axs[1])\n",
    "\n",
    "plt.savefig(f'exports/shape-embeddings-not-mixed-epoch={epoch}.pdf', format='pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664718b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69792fc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X = torch.cat([feats_by_set[set_]['shapes'] for set_ in ['test', 'systematic']]).numpy()\n",
    "all_gts = [torch.full_like(gt_by_set[set_]['shapes'], tidx) for tidx, set_ in enumerate(['test', 'systematic'])]\n",
    "all_gts = torch.cat(all_gts).numpy()\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_2d = pca.fit_transform(X)\n",
    "\n",
    "scatter_pca(X_2d, \n",
    "            all_gts,\n",
    "            labels_to_use=['test', 'systematic'], \n",
    "            special_X=pca.transform(special_X),\n",
    "            special_y=special_gts,\n",
    "            special_labels_to_use=processor.inv_vocabulary, \n",
    "            don_t_label_these=[], \n",
    "            title='Test and Systematic Test')\n",
    "\n",
    "plt.savefig(\n",
    "    f'exports/shape-embeddings-mixed-by-set-epoch={epoch}.pdf', format='pdf', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e928a02",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X = torch.cat([feats_by_set[set_]['shapes'] for set_ in ['test', 'systematic']]).numpy()\n",
    "all_gts = [gt_by_set[set_]['shapes'] for set_ in ['test', 'systematic']]\n",
    "all_gts = torch.cat(all_gts).numpy()\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_2d = pca.fit_transform(X)\n",
    "\n",
    "scatter_pca(X_2d, \n",
    "            all_gts,\n",
    "#             labels_to_use=['test', 'systematic'], \n",
    "            special_X=pca.transform(special_X),\n",
    "            special_y=special_gts,\n",
    "            special_labels_to_use=processor.inv_vocabulary, \n",
    "            don_t_label_these=[], \n",
    "            title='Test and Systematic Test')\n",
    "\n",
    "plt.savefig(\n",
    "    f'exports/shape-embeddings-mixed-by-shape-epoch={epoch}.pdf', format='pdf', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a020277",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4487058",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
