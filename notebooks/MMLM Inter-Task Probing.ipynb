{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc18d515",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-17 15:18:41.933016: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-8.0/lib64/\n",
      "2024-09-17 15:18:41.933044: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/mnt/ialabnas/homes/fidelrio/systematic-text-representations/')\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "import random\n",
    "import pprint\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "from config import load_config\n",
    "from data import build_datasets, build_loader, build_detailed_test_dataloaders\n",
    "from data import CollatorForMaskedSelectedTokens, CollatorForMaskedRandomSelectedTokens, IdentityCollator\n",
    "from data import ALL_POSSIBLE_COLORS\n",
    "from model import MultimodalModel, MultimodalPretrainingModel\n",
    "from utils import load_checkpoint\n",
    "from lightning import Trainer, seed_everything\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from torch.utils.data import DataLoader, Subset, ConcatDataset\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0608ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07b47f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scene_tensor_to_txt(tensor):\n",
    "    return ' '.join([processor.inv_vocabulary[t] for t in tensor.tolist()])\n",
    "\n",
    "def print_scene_tensor(tensor):\n",
    "    scene_text = scene_tensor_to_txt(tensor)\n",
    "    print(scene_text.replace('[PAD]', '').replace('[SEP]','\\n     '))\n",
    "    \n",
    "def print_parallel(tensor0, tensor1, tensor2, confidences, titles):\n",
    "    ttl0, ttl1, ttl2 = titles\n",
    "    print(f'{ttl0:6.6s} {ttl1:6.6s} {ttl2:6.6s}')\n",
    "    for t0, t1, t2, conf in zip(\n",
    "            tensor0.tolist(), tensor1.tolist(), tensor2.tolist(), confidences.tolist()):\n",
    "        w0 = processor.inv_vocabulary[t0]\n",
    "        w1 = processor.inv_vocabulary[t1]\n",
    "        w2 = processor.inv_vocabulary[t2]\n",
    "        \n",
    "        if w0 == '[SEP]':\n",
    "            print()\n",
    "            continue\n",
    "        if w0 == '[PAD]':\n",
    "            break\n",
    "        \n",
    "        print_txt = f'{w0:6.6s} {w1:6.6s} {w2:6.6s} ({conf:.4f})'\n",
    "        if w0 != w2:\n",
    "            print_txt = bold(print_txt)        \n",
    "\n",
    "        print(print_txt)\n",
    "\n",
    "def bold(text):\n",
    "    return (\"\\033[1m\" + text + \"\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbbf4a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a64e591",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 999\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "\n",
    "n_colors = 216\n",
    "epoch = None\n",
    "exp_name = f'mmlm--n_colors={n_colors}c--mlm_probability=0.15'\n",
    "\n",
    "checkpoint = load_checkpoint(exp_name, epoch=epoch)\n",
    "print('Epoch:', checkpoint['epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56aca98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e92f3603",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'epoch=149-step=22050.ckpt'  'epoch=649-step=95550.ckpt'\r\n",
      "'epoch=199-step=29400.ckpt'  'epoch=699-step=102900.ckpt'\r\n",
      "'epoch=19-step=2940.ckpt'    'epoch=69-step=10290.ckpt'\r\n",
      "'epoch=249-step=36750.ckpt'  'epoch=749-step=110250.ckpt'\r\n",
      "'epoch=299-step=44100.ckpt'  'epoch=799-step=117600.ckpt'\r\n",
      "'epoch=29-step=4410.ckpt'    'epoch=79-step=11760.ckpt'\r\n",
      "'epoch=349-step=51450.ckpt'  'epoch=849-step=124950.ckpt'\r\n",
      "'epoch=399-step=58800.ckpt'  'epoch=899-step=132300.ckpt'\r\n",
      "'epoch=39-step=5880.ckpt'    'epoch=89-step=13230.ckpt'\r\n",
      "'epoch=449-step=66150.ckpt'  'epoch=949-step=139650.ckpt'\r\n",
      "'epoch=499-step=73500.ckpt'  'epoch=999-step=147000.ckpt'\r\n",
      "'epoch=49-step=7350.ckpt'    'epoch=99-step=14700.ckpt'\r\n",
      "'epoch=549-step=80850.ckpt'  'epoch=9-step=1470.ckpt'\r\n",
      "'epoch=599-step=88200.ckpt'   last.ckpt\r\n",
      "'epoch=59-step=8820.ckpt'\r\n"
     ]
    }
   ],
   "source": [
    "!ls outputs/$exp_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d1336bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading mmlm--n_colors=216c--mlm_probability=0.15 last checkpoint config from outputs/mmlm--n_colors=216c--mlm_probability=0.15/last.ckpt\n",
      "Add new arg: permute_pixels = False\n",
      "Add new arg: aug_zero_color = False\n"
     ]
    }
   ],
   "source": [
    "config = load_config(exp_name)\n",
    "\n",
    "# config.vocabulary_path = config.vocabulary_path.replace('/workspace/' ,'/workspace1/')\n",
    "# config.base_path = config.base_path.replace('/workspace/' ,'/workspace1/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "671ee85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pp.pprint(vars(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e653b46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset, systematic_dataset, common_systematic_dataset = build_datasets(config)\n",
    "config.pad_idx = train_dataset.pad_idx\n",
    "config.n_tokens = train_dataset.n_tokens\n",
    "\n",
    "complete_dataset = ConcatDataset((test_dataset, systematic_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab071f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loaders = build_detailed_test_dataloaders(test_dataset, config) # type_of_tokens_to_test\n",
    "# systematic_loaders = build_detailed_test_dataloaders(systematic_dataset, config) # type_of_tokens_to_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06c8fe3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fidelrio/.pyenv/versions/systematicity/lib/python3.7/site-packages/lightning/pytorch/utilities/parsing.py:270: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "  f\"Attribute {k!r} is an instance of `nn.Module` and is already saved during checkpointing.\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultimodalModel(config).to(device)\n",
    "training_model = MultimodalPretrainingModel(model, config).to(device)\n",
    "training_model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3ba4dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/workspace1/fidelrio/CLEVR_CoGenT_v1.0/colored-v2/216c/vocab.txt',\n",
       " '/workspace1/fidelrio/CLEVR_CoGenT_v1.0/colored-v2/216c')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.vocabulary_path, config.base_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a26f537b",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = test_dataset.processor\n",
    "mask_token_idx = processor.vocabulary['[MASK]']\n",
    "pad_token_idx = processor.vocabulary['[PAD]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ca80e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "884e2101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collator = CollatorForMaskedLanguageModeling(config, processor)\n",
    "collator = CollatorForMaskedSelectedTokens(config, processor, tokens=color_tokens)\n",
    "# collator = CollatorForMaskedRandomSelectedTokens(config, processor, tokens=shapes_tokens, p=0.2)\n",
    "# collator = IdentityCollator(config, processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1632e2b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08be2d2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca97753c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(max_epochs=config.max_epochs,\n",
    "                  accelerator=\"gpu\",\n",
    "                  devices=torch.cuda.device_count()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d24c802b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = processor.vocabulary\n",
    "\n",
    "relation_tokens = sorted(\n",
    "    [vocab[w] for w in ['left', 'right', 'behind', 'front'] if w in vocab])\n",
    "colors_tokens = sorted(\n",
    "    [vocab[w] for w in ALL_POSSIBLE_COLORS if w in vocab])\n",
    "#     [vocab[w] for w in ['blue', 'brown', 'cyan', 'green', 'red', 'purple', 'yellow', 'gray']])\n",
    "shapes_tokens = sorted(\n",
    "    [vocab[w] for w in ['cylinder', 'sphere', 'cube'] if w in vocab])\n",
    "materials_tokens = sorted(\n",
    "    [vocab[w] for w in ['metal', 'rubber'] if w in vocab])\n",
    "sizes_tokens = sorted(\n",
    "    [vocab[w] for w in ['small', 'large'] if w in vocab])\n",
    "\n",
    "random_baseline = {\n",
    "    'relation':  1 / len(relation_tokens),\n",
    "    'color':  1 / len(color_tokens),\n",
    "    'shapes':  1 / len(shapes_tokens),\n",
    "    'materials':  1 / len(materials_tokens),\n",
    "    'size':  1 / len(size_tokens),\n",
    "    'identity':  1 / len(processor.vocabulary),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7d310a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8316f4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fidelrio/.pyenv/versions/systematicity/lib/python3.7/site-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "scenes_to_sample = 15_000\n",
    "\n",
    "test_indices = random.sample(range(len(test_dataset)), k=scenes_to_sample)\n",
    "pc_subset_test = Subset(test_dataset, test_indices)\n",
    "systematic_indices = random.sample(range(len(systematic_dataset)), k=scenes_to_sample)\n",
    "pc_subset_systematic = Subset(systematic_dataset, systematic_indices)\n",
    "complete_indices = random.sample(range(len(complete_dataset)), k=scenes_to_sample)\n",
    "pc_subset_complete = Subset(complete_dataset, complete_indices)\n",
    "\n",
    "\n",
    "colors_collator = CollatorForMaskedSelectedTokens(config, processor, tokens=colors_tokens)\n",
    "shapes_collator = CollatorForMaskedSelectedTokens(config, processor, tokens=shapes_tokens)\n",
    "materials_collator = CollatorForMaskedSelectedTokens(config, processor, tokens=materials_tokens)\n",
    "sizes_collator = CollatorForMaskedSelectedTokens(config, processor, tokens=sizes_tokens)\n",
    "dlkwargs = {\n",
    "    'batch_size': batch_size,\n",
    "    'num_workers': int(os.environ.get(\"SLURM_CPUS_PER_TASK\", 4)),\n",
    "    'pin_memory': torch.cuda.is_available(),\n",
    "}\n",
    "\n",
    "test_loaders = {}\n",
    "systematic_loaders = {}\n",
    "complete_loaders = {}\n",
    "for task, collator in [('colors', colors_collator),\n",
    "                       ('shapes', shapes_collator),\n",
    "                       ('materials', materials_collator),\n",
    "                       ('sizes', sizes_collator)]:\n",
    "\n",
    "    test_loaders[task] = DataLoader(\n",
    "        pc_subset_test, shuffle=True, collate_fn=collator, **dlkwargs)\n",
    "    systematic_loaders[task] = DataLoader(\n",
    "        pc_subset_systematic, shuffle=True, collate_fn=collator, **dlkwargs)\n",
    "    complete_loaders[task] = DataLoader(\n",
    "        pc_subset_complete, shuffle=True, collate_fn=collator, **dlkwargs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2255ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5593821b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14f5dc6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x7fb075a78e10>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_maps = []  # This will be a list of Tensors, each representing a feature map\n",
    "\n",
    "def hook_feat_map(mod, inp, out):\n",
    "    feature_maps.clear()\n",
    "    feature_maps.append(out)\n",
    "\n",
    "model.transformer.register_forward_hook(hook_feat_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99105f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd6a332e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images.shape, scenes.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "027ae3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['sizes', 'colors', 'materials', 'shapes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2a33f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_properties(scenes, indices=None):\n",
    "    sizes = scenes[:,1:][:,0::5]\n",
    "    colors = scenes[:,1:][:,1::5]\n",
    "    materials = scenes[:,1:][:,2::5]\n",
    "    shapes = scenes[:,1:][:,3::5]\n",
    "\n",
    "    sizes = sizes[sizes != pad_token_idx].cpu()\n",
    "    colors = colors[colors != pad_token_idx].cpu()\n",
    "    materials = materials[materials != pad_token_idx].cpu()\n",
    "    shapes = shapes[shapes != pad_token_idx].cpu()\n",
    "    if indices is not None:\n",
    "        sizes, colors, materials, shapes = sizes[indices], colors[indices], materials[indices], shapes[indices]\n",
    "    return sizes, colors, materials, shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5da467a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:50<00:00,  1.16it/s]\n",
      "100%|██████████| 59/59 [00:50<00:00,  1.18it/s]\n",
      "100%|██████████| 59/59 [00:50<00:00,  1.17it/s]\n",
      "100%|██████████| 59/59 [00:50<00:00,  1.18it/s]\n",
      "100%|██████████| 59/59 [00:50<00:00,  1.17it/s]\n",
      "100%|██████████| 59/59 [00:50<00:00,  1.18it/s]\n",
      "100%|██████████| 59/59 [00:50<00:00,  1.18it/s]\n",
      "100%|██████████| 59/59 [00:50<00:00,  1.18it/s]\n",
      "100%|██████████| 59/59 [00:50<00:00,  1.16it/s]\n",
      "100%|██████████| 59/59 [00:51<00:00,  1.15it/s]\n",
      "100%|██████████| 59/59 [00:50<00:00,  1.18it/s]\n",
      "100%|██████████| 59/59 [00:50<00:00,  1.17it/s]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "feats_by_set = {}\n",
    "gt_by_set = {}\n",
    "props_by_set = {}\n",
    "for test_name, loaders in [\n",
    "        ('test', test_loaders), ('systematic', systematic_loaders), ('complete', complete_loaders)]:\n",
    "    feats_by_task = defaultdict(list)\n",
    "    gt_by_task = defaultdict(list)\n",
    "    props_by_task = defaultdict(list)\n",
    "    for task in tasks:\n",
    "        for images, scenes, labels in tqdm(loaders[task]):\n",
    "            images, scenes, labels = images.to(device), scenes.to(device), labels.to(device)\n",
    "            cimages, cscenes, clabels = images, scenes, labels\n",
    "            with torch.no_grad():\n",
    "                output_logits = model(images, scenes)\n",
    "\n",
    "                features = feature_maps[0]\n",
    "                confidences = softmax(output_logits, dim=-1).max(dim=-1).values\n",
    "                predictions = output_logits.argmax(dim=-1)\n",
    "\n",
    "                scene_features = features.transpose(1,0)[:,-config.max_scene_size:]\n",
    "                mask_idxs = (scenes == mask_token_idx)\n",
    "                \n",
    "                gts = labels[:,-config.max_scene_size:][mask_idxs].cpu()\n",
    "                feats = scene_features[mask_idxs].cpu()\n",
    "                props = get_properties(scenes)               \n",
    "                \n",
    "                gt_by_task[task].append(gts)\n",
    "                feats_by_task[task].append(feats)\n",
    "                props_by_task[task].append(props)\n",
    "   \n",
    "    feats_by_set[test_name] = feats_by_task\n",
    "    gt_by_set[test_name] = gt_by_task\n",
    "    props_by_set[test_name] = props_by_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a8984b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "109feeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_name, feats_by_tasks in feats_by_set.items():\n",
    "    for task_name, feats in feats_by_tasks.items():\n",
    "        task_idx = tasks.index(task_name)\n",
    "        feats_by_set[test_name][task_name] = torch.cat(feats)\n",
    "        gt_by_set[test_name][task_name] = torch.cat(gt_by_set[test_name][task_name])    \n",
    "        props_by_set[test_name][task_name] = torch.stack(\n",
    "            [torch.cat(prop) for prop in zip(*props_by_set[test_name][task_name])], dim=-1)\n",
    "        \n",
    "        props_by_set[test_name][task_name][:,task_idx] = gt_by_set[test_name][task_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "04c697ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([96807, 256]), torch.Size([96807, 4]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_by_set[test_name][task_name].shape, props_by_set[test_name][task_name].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c7908476",
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_to_sample = 15_000\n",
    "\n",
    "for test_name in feats_by_set:\n",
    "    for task_name in feats_by_set[test_name]:\n",
    "        object_indices = random.sample(range(len(feats_by_set[test_name][task_name])), k=objects_to_sample) \n",
    "        \n",
    "        feats_by_set[test_name][task_name] = feats_by_set[test_name][task_name][object_indices]\n",
    "        gt_by_set[test_name][task_name] = gt_by_set[test_name][task_name][object_indices]\n",
    "        props_by_set[test_name][task_name] = props_by_set[test_name][task_name][object_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9f748be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([15000, 256]), torch.Size([15000, 4]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_by_set[test_name][task_name].shape, props_by_set[test_name][task_name].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ca11a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a3d810e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save({\n",
    "#     'feats_by_set': feats_by_set,\n",
    "#     'props_by_set': props_by_set,\n",
    "# }, 'feats-tmp.pt')\n",
    "\n",
    "# !ls -lah feats-tmp.pt\n",
    "# !rm feats-tmp.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa88a2e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb323122",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fe9b7d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.optim import SGD\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "from collections import defaultdict\n",
    "from torch.nn import functional as F\n",
    "from tqdm.auto import tqdm\n",
    "import copy\n",
    "\n",
    "\n",
    "def create_linear_probe(n_features, hidden_size, n_targets):\n",
    "    if isinstance(hidden_size, list):\n",
    "        hidden_sizes = hidden_size\n",
    "    else:\n",
    "        hidden_sizes = [hidden_size]\n",
    "\n",
    "    if n_targets == 2:\n",
    "        n_targets = 1\n",
    "\n",
    "    prev_hidden_size = hidden_sizes.pop(0)\n",
    "    layers = [nn.Linear(n_features, prev_hidden_size)]\n",
    "    for hidden_size in hidden_sizes:\n",
    "        layers.append(nn.Linear(prev_hidden_size, hidden_size))\n",
    "        prev_hidden_size = hidden_size\n",
    "    layers.append(nn.Linear(prev_hidden_size, n_targets))\n",
    "    linear_probe = nn.Sequential(*layers)\n",
    "    \n",
    "    for p in linear_probe:\n",
    "        try:\n",
    "            nn.init.kaiming_uniform_(p.weight)\n",
    "        except AttributeError:\n",
    "            pass\n",
    "\n",
    "    linear_probe = linear_probe.to(device)\n",
    "    return linear_probe\n",
    "    \n",
    "def train(linear_probe,\n",
    "          optimizer,\n",
    "          train_loader,\n",
    "          val_loader,\n",
    "          num_epochs,\n",
    "          patience,\n",
    "          n_targets):\n",
    "    \n",
    "    wait = 0\n",
    "    best_model = None\n",
    "    best_val_relevant_metric = 0\n",
    "\n",
    "    is_binary_task = n_targets == 2\n",
    "    criterion = F.binary_cross_entropy_with_logits if is_binary_task else F.cross_entropy\n",
    "    \n",
    "    linear_probe.train()\n",
    "\n",
    "    metrics = defaultdict(list)\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        linear_probe.train()\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            logit_pred = linear_probe(x).squeeze()\n",
    "            y = y.float() if is_binary_task else y\n",
    "            loss = criterion(logit_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            metrics['loss'].append(float(loss))\n",
    "            if is_binary_task:\n",
    "                pred = torch.sigmoid(logit_pred) > 0.5\n",
    "                train_acc = (pred == y).sum() / y.shape[0]\n",
    "                metrics['train_acc'].append(float(train_acc))\n",
    "#                 prec, recall, f1 = calc_prec_recall_f1(pred, y)\n",
    "#                 metrics['train_prec'].append(float(prec))\n",
    "#                 metrics['train_recall'].append(float(recall))\n",
    "#                 metrics['train_f1'].append(float(f1))\n",
    "            else:\n",
    "                pred = logit_pred.argmax(-1)\n",
    "                train_acc = (pred == y).sum() / y.shape[0]\n",
    "                metrics['train_acc'].append(float(train_acc))\n",
    "                \n",
    "                \n",
    "        linear_probe.eval()\n",
    "        cum_sum = 0\n",
    "        cum_loss = 0\n",
    "        cum_logit_pred, cum_y = [], []\n",
    "        for x, y in val_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            bsz = x.shape[0]\n",
    "            logit_pred = linear_probe(x).squeeze()\n",
    "            y = y.float() if is_binary_task else y\n",
    "            loss = criterion(logit_pred, y)\n",
    "            cum_loss += float(loss) * bsz\n",
    "            \n",
    "            cum_logit_pred.append(logit_pred)\n",
    "            cum_y.append(y)\n",
    "\n",
    "        logit_pred = torch.cat(cum_logit_pred)\n",
    "        y = torch.cat(cum_y)\n",
    "\n",
    "        val_loss = cum_loss / len(val_dataset)\n",
    "        metrics['val_loss'].append(float(val_loss))\n",
    "        if is_binary_task:\n",
    "            pred = torch.sigmoid(logit_pred) > 0.5\n",
    "            val_acc = (pred == y).sum() / y.shape[0]\n",
    "            metrics['val_acc'].append(float(val_acc))\n",
    "#             prec, recall, f1 = calc_prec_recall_f1(pred, y)\n",
    "#             metrics['val_prec'].append(float(prec))\n",
    "#             metrics['val_recall'].append(float(recall))\n",
    "#             metrics['val_f1'].append(float(f1))\n",
    "        else:\n",
    "            pred = logit_pred.argmax(-1)\n",
    "            val_acc = (pred == y).sum() / y.shape[0]\n",
    "            metrics['val_acc'].append(float(val_acc))\n",
    "\n",
    "        # Early stopping\n",
    "        val_relevant_metric = metrics['val_acc'][-1]\n",
    "#         val_relevant_metric = metrics['val_f1'][-1] if is_binary_task else metrics['val_acc'][-1]\n",
    "        if val_relevant_metric > best_val_relevant_metric:\n",
    "            best_val_relevant_metric = val_relevant_metric\n",
    "            best_model = copy.deepcopy(linear_probe)\n",
    "            wait = 0\n",
    "        else:\n",
    "            wait += 1\n",
    "\n",
    "        if wait > patience:\n",
    "            break\n",
    "\n",
    "    print(f'Finished in epoch {epoch}')\n",
    "    return best_model, metrics, best_val_relevant_metric\n",
    "\n",
    "def calc_prec_recall_f1(pred, y):\n",
    "    p, r, f1, _ = precision_recall_fscore_support(\n",
    "        y.cpu().detach().numpy(),\n",
    "        pred.cpu().detach().numpy(),\n",
    "        beta=1,\n",
    "    )\n",
    "    return p[1], r[1], f1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64946702",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "afd09884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sizes', 'colors', 'materials', 'shapes']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "301a3c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_name = 'complete'\n",
    "feat_task_name = 'shapes'\n",
    "gt_task_name = 'colors'\n",
    "\n",
    "X = feats_by_set[test_name][feat_task_name]\n",
    "y = props_by_set[test_name][feat_task_name][:,tasks.index(gt_task_name)]\n",
    "\n",
    "tokens_to_class_map = {t: i for i, t in enumerate(set(y.tolist()))}\n",
    "y = y.apply_(tokens_to_class_map.get) # transform to classes\n",
    "\n",
    "X_train = X[:10_000,:].cuda()\n",
    "X_val = X[10_000:12500,:].cuda()\n",
    "X_test = X[12500:,:].cuda()\n",
    "y_train = y[:10_000].cuda()\n",
    "y_val = y[10_000:12500].cuda()\n",
    "y_test = y[12500:].cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2eb1090a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([15000, 256]), torch.Size([15000, 4]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_by_set[test_name][feat_task_name].shape, props_by_set[test_name][feat_task_name].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab230b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9119d9b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "21116dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1fa8ce75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 216)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features = X.size(1)\n",
    "n_targets = len(tokens_to_class_map)\n",
    "\n",
    "n_features, n_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2b62dd41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start experiment: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "335d9e7c5bf84d26a3bf3001ca3eeb9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in epoch 58\n",
      "hidden_size=32 lr=0.01\n",
      "Best val acc:  0.8163999915122986\n",
      "\n",
      "\n",
      "Start experiment: 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcddda399a7f4f5d9d5b75532c3efe05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in epoch 352\n",
      "hidden_size=32 lr=0.001\n",
      "Best val acc:  0.7955999970436096\n",
      "\n",
      "\n",
      "Start experiment: 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7da6e081c2dd4632b8bb782e6507a352",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in epoch 499\n",
      "hidden_size=32 lr=0.0001\n",
      "Best val acc:  0.46959999203681946\n",
      "\n",
      "\n",
      "Start experiment: 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc9ef7347e08473382c658a83721c221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in epoch 62\n",
      "hidden_size=64 lr=0.01\n",
      "Best val acc:  0.8351999521255493\n",
      "\n",
      "\n",
      "Start experiment: 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd4c6aad619d48559c63e43412f5f85e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in epoch 261\n",
      "hidden_size=64 lr=0.001\n",
      "Best val acc:  0.8151999711990356\n",
      "\n",
      "\n",
      "Start experiment: 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59e393f26f104abba8f15d403bade819",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in epoch 499\n",
      "hidden_size=64 lr=0.0001\n",
      "Best val acc:  0.6599999666213989\n",
      "\n",
      "\n",
      "Start experiment: 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cf413213a4945ab90e34b9c99578226",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in epoch 94\n",
      "hidden_size=128 lr=0.01\n",
      "Best val acc:  0.8399999737739563\n",
      "\n",
      "\n",
      "Start experiment: 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1a8dd55a4ca4e3d94ebbdb53188188f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in epoch 161\n",
      "hidden_size=128 lr=0.001\n",
      "Best val acc:  0.8187999725341797\n",
      "\n",
      "\n",
      "Start experiment: 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f0cd3d21b9c4ad8896511b67d869921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in epoch 499\n",
      "hidden_size=128 lr=0.0001\n",
      "Best val acc:  0.736799955368042\n",
      "\n",
      "\n",
      "best_hidden_size: 128\n",
      "best_lr: 0.01\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "is_binary_task = n_targets == 2\n",
    "relevant_metric_name = 'f1' if is_binary_task else 'acc'\n",
    "\n",
    "all_metrics = {}\n",
    "grid_best_relevant_metric = 0\n",
    "grid_best_model = None\n",
    "grid_best_metrics = None\n",
    "best_hidden_size = None\n",
    "best_lr = None\n",
    "for exp_idx, (hidden_size, lr) in enumerate(product([32, 64, 128],\n",
    "                                                    [1e-2, 1e-3, 1e-4]), start=1):\n",
    "\n",
    "    print(f'Start experiment: {exp_idx}')\n",
    "\n",
    "    linear_probe = create_linear_probe(n_features, [hidden_size, hidden_size], n_targets)\n",
    "    optimizer = SGD(linear_probe.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "    best_model, metrics, best_relevant_metric = train(linear_probe,\n",
    "                                                      optimizer,\n",
    "                                                      train_loader,\n",
    "                                                      val_loader,\n",
    "                                                      num_epochs=500,\n",
    "                                                      patience=20,\n",
    "                                                      n_targets=n_targets,\n",
    "                                                     )\n",
    "    \n",
    "    all_metrics[(hidden_size, lr)] = metrics\n",
    "    if  best_relevant_metric > grid_best_relevant_metric:\n",
    "        best_hidden_size = hidden_size\n",
    "        best_lr = lr\n",
    "        grid_best_model = best_model\n",
    "        grid_best_metrics = metrics\n",
    "        grid_best_relevant_metric = best_relevant_metric\n",
    "\n",
    "\n",
    "    linear_probe = optimizer = None\n",
    "\n",
    "    print(f'hidden_size={hidden_size} lr={lr}')\n",
    "    print(f'Best val {relevant_metric_name}: ', float(best_relevant_metric))\n",
    "    print('\\n')\n",
    "\n",
    "print('best_hidden_size:', best_hidden_size)\n",
    "print('best_lr:', best_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b243b9fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a18acc21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07d2c566eac7439a8791fed2a18c3395",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# is_binary_task = len(set(group.values())) == 2\n",
    "criterion = F.binary_cross_entropy_with_logits if is_binary_task else F.cross_entropy\n",
    "\n",
    "grid_best_model.eval()\n",
    "cum_loss = 0\n",
    "cum_logit_pred = []\n",
    "cum_y = []\n",
    "for x, y in tqdm(test_loader):\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    bsz = x.shape[0]\n",
    "    logit_pred = grid_best_model(x).squeeze()\n",
    "    y = y.float() if is_binary_task else y\n",
    "    cum_logit_pred.append(logit_pred)\n",
    "    cum_y.append(y)\n",
    "    loss = criterion(logit_pred, y)\n",
    "    cum_loss += float(loss) * bsz\n",
    "\n",
    "\n",
    "logit_pred = torch.cat(cum_logit_pred)\n",
    "y = torch.cat(cum_y)\n",
    "grid_best_metrics['test_loss'] = (cum_loss / len(test_dataset))\n",
    "if is_binary_task:\n",
    "    pred = torch.sigmoid(logit_pred) > 0.5\n",
    "    train_acc = (pred == y).sum() / y.shape[0]\n",
    "    grid_best_metrics['test_acc'] = float(train_acc)\n",
    "#     prec, recall, f1 = calc_prec_recall_f1(pred, y)\n",
    "#     grid_best_metrics['test_prec'] = float(prec)\n",
    "#     grid_best_metrics['test_recall'] = float(recall)\n",
    "#     grid_best_metrics['test_f1'] = float(f1)\n",
    "else:\n",
    "    pred = logit_pred.argmax(-1)\n",
    "    test_acc = (pred == y).sum() / y.shape[0]\n",
    "    grid_best_metrics['test_acc'] = float(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5818fdf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc:  0.8283999562263489\n"
     ]
    }
   ],
   "source": [
    "print('test_acc: ', grid_best_metrics['test_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb92cff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c212ceae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'train_acc', 'val_loss', 'val_acc', 'test_loss', 'test_acc'])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_best_metrics.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c737a95b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
