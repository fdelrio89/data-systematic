{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc18d515",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/mnt/ialabnas/homes/fidelrio/systematic-text-representations/')\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "import random\n",
    "import pprint\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "\n",
    "from config import load_config\n",
    "from data import build_datasets, build_loader\n",
    "from data import (CollatorForMaskedLanguageModeling,\n",
    "                  CollatorForMaskedSelectedTokens,\n",
    "                  CollatorForMaskedRandomSelectedTokens,\n",
    "                  IdentityCollator)\n",
    "from data import ALL_POSSIBLE_COLORS\n",
    "from model import MultimodalModel, MultimodalPretrainingModel\n",
    "from utils import load_checkpoint\n",
    "from lightning import Trainer, seed_everything\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0608ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07b47f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scene_tensor_to_txt(tensor):\n",
    "    return ' '.join([processor.inv_vocabulary[t] if t != -100 else '[NONE]' for t in tensor.tolist()])\n",
    "\n",
    "def print_scene_tensor(tensor):\n",
    "    scene_text = scene_tensor_to_txt(tensor)\n",
    "    print(scene_text.replace('[PAD]', '').replace('[SEP]','\\n     '))\n",
    "    \n",
    "def print_parallel(tensor0, tensor1, tensor2, confidences, titles):\n",
    "    ttl0, ttl1, ttl2 = titles\n",
    "    print(f'{ttl0:6.6s} {ttl1:6.6s} {ttl2:6.6s}')\n",
    "    for t0, t1, t2, conf in zip(\n",
    "            tensor0.tolist(), tensor1.tolist(), tensor2.tolist(), confidences.tolist()):\n",
    "        w0 = processor.inv_vocabulary[t0]\n",
    "        w1 = processor.inv_vocabulary[t1]\n",
    "        w2 = processor.inv_vocabulary[t2]\n",
    "        \n",
    "        if w0 == '[SEP]':\n",
    "            print()\n",
    "            continue\n",
    "        if w0 == '[PAD]':\n",
    "            break\n",
    "        \n",
    "        print_txt = f'{w0:6.6s} {w1:6.6s} {w2:6.6s} ({conf:.4f})'\n",
    "        if w0 != w2:\n",
    "            print_txt = bold(print_txt)\n",
    "            \n",
    "\n",
    "        print(print_txt)\n",
    "        \n",
    "def bold(text):\n",
    "    return (\"\\033[1m\" + text + \"\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a64e591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 999\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "\n",
    "n_colors = '8c'\n",
    "epoch = None\n",
    "# exp_name = f'mmlm--n_colors={n_colors}c--mlm_probability=0.15'\n",
    "exp_name = f'mmlm--n_colors={n_colors}--mlm_probability=0.15'\n",
    "\n",
    "checkpoint = load_checkpoint(exp_name, epoch=epoch)\n",
    "print('Epoch:', checkpoint['epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d1336bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading mmlm--n_colors=8c--mlm_probability=0.15 last checkpoint config from outputs/mmlm--n_colors=8c--mlm_probability=0.15/last.ckpt\n",
      "Add new arg: trainset_subset = 1.0\n",
      "Add new arg: permute_pixels = False\n",
      "Add new arg: color_jitter = False\n",
      "Add new arg: color_jitter_brightness = 0.0\n",
      "Add new arg: color_jitter_hue = 0.0\n",
      "Add new arg: color_jitter_saturation = 0.0\n",
      "Add new arg: color_jitter_contrast = 0.0\n",
      "Add new arg: aug_zero_color = False\n"
     ]
    }
   ],
   "source": [
    "config = load_config(exp_name)\n",
    "\n",
    "config.vocabulary_path = config.vocabulary_path.replace('/workspace/' ,'/workspace1/')\n",
    "# config.vocabulary_path = f'/mnt/ialabnas/homes/fidelrio/clevr-dataset-gen/output/vocab-{n_colors}.txt'\n",
    "config.base_path = config.base_path.replace('/workspace/' ,'/workspace1/')\n",
    "# config.base_path = f'/mnt/ialabnas/homes/fidelrio/clevr-dataset-gen/output/multicolored-v2/{n_colors}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd8b554",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec6305cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.episodic_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23aded44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 125c\t\t  27e1_1\t '64c_3_ep=256'   64e2_10\t'8c_1_pb=1.0'\r\n",
      " 125e1_1\t  27e1_10\t '64c_3_ep=64'\t  64e2_2\t 8c2\r\n",
      " 125e1_2\t  27e1_2\t '64c_3_pb=0.5'   64e2_3\t'8c_2_pb=0.5'\r\n",
      " 125e1_3\t  27e1_3\t '64c_3_pb=1.0'   64e2_4\t'8c_2_pb=1.0'\r\n",
      " 125e1_4\t  27e1_4\t '64c_3_pb=256'   64e2_5\t 8c3\r\n",
      " 125e1_5\t  27e1_5\t '64c_4_ep=256'   64e2_6\t'8c_3_pb=0.5'\r\n",
      " 216c\t\t  27e1_6\t '64c_4_ep=64'\t  64e2_7\t'8c_3_pb=1.0'\r\n",
      "'216c_1_ep=256'   27e1_7\t '64c_4_pb=0.5'   64e2_8\t 8c4\r\n",
      "'216c_1_ep=64'\t  27e1_8\t '64c_4_pb=1.0'   64e2_9\t'8c_4_pb=0.5'\r\n",
      " 216c2\t\t  27e1_9\t '64c_4_pb=256'   64e3_1\t'8c_4_pb=1.0'\r\n",
      "'216c_2_ep=256'   27e2_1\t '64c_5_ep=256'   64e3_10\t 8c5\r\n",
      "'216c_2_ep=64'\t  27e2_2\t '64c_5_ep=64'\t  64e3_2\t'8c_5_pb=0.5'\r\n",
      " 216c3\t\t  27e2_3\t '64c_5_pb=0.5'   64e3_3\t'8c_5_pb=1.0'\r\n",
      "'216c_3_ep=256'   27e2_4\t '64c_5_pb=1.0'   64e3_4\t 8d1\r\n",
      "'216c_3_ep=64'\t  27e2_5\t '64c_5_pb=256'   64e3_5\t 8d2\r\n",
      " 216c4\t\t  64c\t\t  64e1_1\t  64e3_6\t 8d3\r\n",
      "'216c_4_ep=256'  '64c_1_ep=256'   64e1_10\t  64e3_7\t 8e1_1\r\n",
      "'216c_4_ep=64'\t '64c_1_ep=64'\t  64e1_2\t  64e3_8\t 8e1_2\r\n",
      " 216c5\t\t '64c_1_pb=0.5'   64e1_3\t  64e3_9\t 8e2_1\r\n",
      "'216c_5_ep=256'  '64c_1_pb=1.0'   64e1_4\t  64e4_1\t 8e2_2\r\n",
      "'216c_5_ep=64'\t '64c_1_pb=256'   64e1_5\t  64e4_2\t 8e3_1\r\n",
      " 216d1\t\t '64c_2_ep=256'   64e1_6\t  64e4_3\t 8e3_2\r\n",
      " 216d2\t\t '64c_2_ep=64'\t  64e1_7\t  64e4_4\r\n",
      " 216d3\t\t '64c_2_pb=0.5'   64e1_8\t  64e4_5\r\n",
      " 216d4\t\t '64c_2_pb=1.0'   64e1_9\t  8c1\r\n",
      " 27c\t\t '64c_2_pb=256'   64e2_1\t '8c_1_pb=0.5'\r\n"
     ]
    }
   ],
   "source": [
    "!ls /mnt/ialabnas/homes/fidelrio/clevr-dataset-gen/output/multicolored-v2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "671ee85c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pp.pprint(vars(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e653b46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building CLEVRMultimodalSplit\n"
     ]
    }
   ],
   "source": [
    "train_dataset, test_dataset, systematic_dataset, common_systematic_dataset = build_datasets(config)\n",
    "config.pad_idx = train_dataset.pad_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcba0aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06c8fe3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fidelrio/.pyenv/versions/systematicity/lib/python3.7/site-packages/lightning/pytorch/utilities/parsing.py:270: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "  f\"Attribute {k!r} is an instance of `nn.Module` and is already saved during checkpointing.\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultimodalModel(config)\n",
    "training_model = MultimodalPretrainingModel(model, config)\n",
    "training_model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1adc0a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69e5b1ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5572448"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ba4dfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a26f537b",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = test_dataset.processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa7f06bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_tokens = sorted([processor.vocabulary[w] for w in ['left', 'right', 'behind', 'front']])\n",
    "color_tokens = sorted(\n",
    "    [processor.vocabulary[w] for w in ALL_POSSIBLE_COLORS if w in processor.vocabulary])\n",
    "shapes_tokens = sorted([processor.vocabulary[w] for w in ['cylinder', 'sphere', 'cube']])\n",
    "materials_tokens = sorted([processor.vocabulary[w] for w in ['metal', 'rubber']])\n",
    "size_tokens = sorted([processor.vocabulary[w] for w in ['small', 'large']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8a8124",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2ca80e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [w for w in ALL_POSSIBLE_COLORS if w in processor.vocabulary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "027ec66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set([w for w in ALL_POSSIBLE_COLORS if '#' in w]) & set([w for w in processor.vocabulary.keys() if '#' in w])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1bb04cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoGenT_A.json  CoGenT_B.json  images  properties.json  scenes  vocab.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls /workspace1/fidelrio/CLEVR_CoGenT_v1.0/colored-v2/216c/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fcae7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eea8e938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import default_collate\n",
    "\n",
    "# class CollatorForMaskedSelectedTokens:\n",
    "#     def __init__(self, config, processor, tokens, dont_mask_spheres=False):\n",
    "#         self.config = config\n",
    "#         self.token_to_mask_idxs = torch.tensor(tokens).long()\n",
    "#         self.special_token_idxs = torch.tensor(processor.special_token_idxs).long()\n",
    "#         self.mask_token_idx = processor.mask_token_idx\n",
    "#         self.image_patch_sizes = config.patch_height, config.patch_width\n",
    "#         self.dont_mask_spheres = dont_mask_spheres\n",
    "#         self.sphere_token_idx = processor.vocabulary['sphere']\n",
    "\n",
    "#     def __call__(self, batch):\n",
    "#         images, scenes = default_collate(batch)\n",
    "#         scenes, scenes_labels = self.build_targets(scenes)\n",
    "#         images_labels = self.build_null_image_targets(images)\n",
    "#         labels = torch.cat((images_labels, scenes_labels), dim=1)\n",
    "#         return images, scenes, labels\n",
    "\n",
    "#     def build_null_image_targets(self, images):\n",
    "#         b, *_ = images.shape\n",
    "#         n_patches = self.config.n_patches\n",
    "#         return torch.full((b, n_patches), -100)\n",
    "\n",
    "#     def build_targets(self, inputs):\n",
    "#         labels = inputs.clone()\n",
    "#         masked_indices = torch.isin(labels, self.token_to_mask_idxs)\n",
    "#         if self.dont_mask_spheres:\n",
    "#             sphere_token_mask = inputs == self.sphere_token_idx\n",
    "#             sphere_mask = (torch.roll(sphere_token_mask, shifts=-3, dims=1) |\n",
    "#                            torch.roll(sphere_token_mask, shifts=-2, dims=1) |\n",
    "#                            torch.roll(sphere_token_mask, shifts=-1, dims=1) |\n",
    "#                            sphere_token_mask)\n",
    "#             masked_indices = masked_indices & ~sphere_mask\n",
    "            \n",
    "#         labels[~masked_indices] = -100\n",
    "#         inputs[masked_indices] = self.mask_token_idx\n",
    "\n",
    "#         return inputs, labels\n",
    "\n",
    "\n",
    "# class CollatorForMaskedRandomSelectedTokens:\n",
    "#     def __init__(self, config, processor, tokens, p, dont_mask_spheres=False):\n",
    "#         self.config = config\n",
    "#         self.token_to_mask_idxs = torch.tensor(tokens).long()\n",
    "#         self.special_token_idxs = torch.tensor(processor.special_token_idxs).long()\n",
    "#         self.mask_token_idx = processor.mask_token_idx\n",
    "#         self.image_patch_sizes = config.patch_height, config.patch_width\n",
    "#         self.p = p\n",
    "#         self.dont_mask_spheres = dont_mask_spheres\n",
    "#         self.sphere_token_idx = processor.vocabulary['sphere']\n",
    "\n",
    "#     def __call__(self, batch):\n",
    "#         images, scenes = default_collate(batch)\n",
    "#         scenes, scenes_labels = self.build_targets(scenes)\n",
    "#         images_labels = self.build_null_image_targets(images)\n",
    "#         labels = torch.cat((images_labels, scenes_labels), dim=1)\n",
    "#         return images, scenes, labels\n",
    "\n",
    "#     def build_null_image_targets(self, images):\n",
    "#         b, *_ = images.shape\n",
    "#         n_patches = self.config.n_patches\n",
    "#         return torch.full((b, n_patches), -100)\n",
    "\n",
    "#     def build_targets(self, inputs):\n",
    "#         labels = inputs.clone()\n",
    "#         masked_indices = torch.isin(labels, self.token_to_mask_idxs)\n",
    "#         is_selected = torch.bernoulli(torch.full_like(labels, self.p, dtype=torch.float)).bool()\n",
    "#         masked_indices = masked_indices & is_selected\n",
    "#         if self.dont_mask_spheres:\n",
    "#             sphere_token_mask = inputs == self.sphere_token_idx\n",
    "#             sphere_mask = (torch.roll(sphere_token_mask, shifts=-3, dims=1) |\n",
    "#                            torch.roll(sphere_token_mask, shifts=-2, dims=1) |\n",
    "#                            torch.roll(sphere_token_mask, shifts=-1, dims=1) |\n",
    "#                            sphere_token_mask)\n",
    "#             masked_indices = masked_indices & ~sphere_mask\n",
    "            \n",
    "#         labels[~masked_indices] = -100\n",
    "#         inputs[masked_indices] = self.mask_token_idx\n",
    "\n",
    "#         return inputs, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "884e2101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collator = CollatorForMaskedLanguageModeling(config, processor)\n",
    "# collator = CollatorForMaskedSelectedTokens(config, processor, tokens=color_tokens, dont_mask_spheres=True)\n",
    "collator = CollatorForMaskedRandomSelectedTokens(config, processor, tokens=color_tokens, p=0.8, dont_mask_spheres=True)\n",
    "# collator = IdentityCollator(config, processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac29ffab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75d0e90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85f61f13",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'episode_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-880306a52072>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt/ialabnas/homes/fidelrio/systematic-text-representations/data.py\u001b[0m in \u001b[0;36mbuild_loader\u001b[0;34m(dataset, config, shuffle, collate_fn)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mscenes_or_questions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquestions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mdlkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_sampler'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEpisodicBatchSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscenes_or_questions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mdlkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/ialabnas/homes/fidelrio/systematic-text-representations/data.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch_size, scenes_or_questions)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples_by_episode_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_or_q\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscenes_or_questions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples_by_episode_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms_or_q\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'episode_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'episode_id'"
     ]
    }
   ],
   "source": [
    "train_loader = build_loader(train_dataset, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058ab44e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eeb213c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a772c06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddee22b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_idx = 1\n",
    "sample_idx = random.randint(0, len(test_dataset))\n",
    "image, scene = test_dataset.retrieve_raw(sample_idx)\n",
    "image_tensor, scene_tensor = test_dataset[sample_idx]\n",
    "\n",
    "collated_images, collated_scenes, collated_labels = collator([(image_tensor, scene_tensor)])\n",
    "\n",
    "print(sample_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2f3561",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print_scene_tensor(scene_tensor)\n",
    "print()\n",
    "print_scene_tensor(collated_scenes[0])\n",
    "\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c49cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_scene_tensor(scene_tensor)\n",
    "# print()\n",
    "# print_scene_tensor(collated_scenes[0])\n",
    "# print()\n",
    "# print_scene_tensor(collated_labels[0,-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed622b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3880d3c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14365ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "to_properties = lambda object_: (object_['size'], object_['material'], object_['color'], object_['shape'])\n",
    "\n",
    "def to_object_sets(objects):\n",
    "    c = Counter()\n",
    "    object_set = set()\n",
    "    for object_ in objects:\n",
    "        object_properties = to_properties(object_)\n",
    "        id_ = c[object_properties]\n",
    "        c[object_properties] += 1\n",
    "        object_set.add(tuple([id_, *object_properties]))\n",
    "\n",
    "    return object_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb070b6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e71c419",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14647fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = random.randint(0, len(test_dataset))\n",
    "image, scene = test_dataset.retrieve_raw(sample_idx)\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f2799d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchvision.transforms import v2\n",
    "from torchvision import transforms\n",
    "jitter = transforms.ColorJitter(brightness=.0, hue=.5, contrast=.0, saturation=.0)\n",
    "\n",
    "jitter(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e9f00e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111c199a",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, scenes = train_dataset[sample_idx]\n",
    "images, scenes = images.unsqueeze(0), scenes.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e2c36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sphere_token_idx = processor.vocabulary['sphere']\n",
    "sphere_token_mask = scenes == sphere_token_idx\n",
    "sphere_mask = (torch.roll(sphere_token_mask, shifts=-3, dims=1) |\n",
    "               torch.roll(sphere_token_mask, shifts=-2, dims=1) |\n",
    "               torch.roll(sphere_token_mask, shifts=-1, dims=1) |\n",
    "               sphere_token_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c1c08a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19558776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# dataset = train_dataset\n",
    "\n",
    "# with open(config.base_path + f'/CoGenT_A.json') as fp:\n",
    "#     color_dist = json.load(fp)\n",
    "\n",
    "# common_colors = set(color_dist['cube']) & set(color_dist['cylinder'])\n",
    "# cmn_colors_in_image = np.array([\n",
    "#     np.mean([o['color'] in common_colors for o in scene['objects']])\n",
    "#     for scene in dataset.scenes\n",
    "# ])\n",
    "\n",
    "# CUTS = [0.9,0.8,0.7,0.6,0.5,0.4,0.3,0.2,0.1,-0.0]\n",
    "\n",
    "# subsets = []\n",
    "# for cut in CUTS:\n",
    "#     indices = np.argwhere(cmn_colors_in_image >= cut)[:,0].tolist()\n",
    "#     subsets.append(Subset(dataset, indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da997a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [len(s) for s in subsets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6ce48e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7ba041",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc27064",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_logits = model(collated_images, collated_scenes)\n",
    "\n",
    "confidences = softmax(output_logits, dim=-1).max(dim=-1).values\n",
    "predictions = output_logits.argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd8f0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_parallel(\n",
    "    scene_tensor,\n",
    "    collated_scenes[0],\n",
    "    predictions[0][-config.max_scene_size:],\n",
    "    confidences[0][-config.max_scene_size:],\n",
    "    titles=['gd_tth', 'input', 'output']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1632e2b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08be2d2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca97753c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(max_epochs=config.max_epochs,\n",
    "                  accelerator=\"gpu\",\n",
    "                  devices=torch.cuda.device_count()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e50bf61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24c802b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = processor.vocabulary\n",
    "\n",
    "relation_tokens = sorted(\n",
    "    [vocab[w] for w in ['left', 'right', 'behind', 'front'] if w in vocab])\n",
    "color_tokens = sorted(\n",
    "    [vocab[w] for w in ALL_POSSIBLE_COLORS if w in vocab])\n",
    "#     [vocab[w] for w in ['blue', 'brown', 'cyan', 'green', 'red', 'purple', 'yellow', 'gray']])\n",
    "shapes_tokens = sorted(\n",
    "    [vocab[w] for w in ['cylinder', 'sphere', 'cube'] if w in vocab])\n",
    "materials_tokens = sorted(\n",
    "    [vocab[w] for w in ['metal', 'rubber'] if w in vocab])\n",
    "size_tokens = sorted(\n",
    "    [vocab[w] for w in ['small', 'large'] if w in vocab])\n",
    "\n",
    "random_baseline = {\n",
    "    'relation':  1 / len(relation_tokens),\n",
    "    'color':  1 / len(color_tokens),\n",
    "    'shapes':  1 / len(shapes_tokens),\n",
    "    'materials':  1 / len(materials_tokens),\n",
    "    'size':  1 / len(size_tokens),\n",
    "    'identity':  1 / len(processor.vocabulary),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f065ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617f6b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1b03ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_original = test_dataset\n",
    "systematic_dataset_original = systematic_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73416785",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = random.sample(range(len(train_dataset)), k=500)\n",
    "train_dataset_subset = Subset(train_dataset, train_indices)\n",
    "test_indices = random.sample(range(len(test_dataset)), k=500)\n",
    "test_dataset_subset = Subset(test_dataset, test_indices)\n",
    "systematic_indices = random.sample(range(len(systematic_dataset)), k=500)\n",
    "systematic_dataset_subset = Subset(systematic_dataset, systematic_indices)\n",
    "common_systematic_indices = random.sample(range(len(common_systematic_dataset)), k=500)\n",
    "common_systematic_dataset_subset = Subset(common_systematic_dataset, systematic_indices)\n",
    "\n",
    "\n",
    "# train_dataset_subset = train_dataset\n",
    "# test_dataset_subset = test_dataset\n",
    "# systematic_dataset_subset = systematic_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35be82f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "collate_fns = {\n",
    "    'selected': [\n",
    "        ('color', CollatorForMaskedSelectedTokens(config, processor, tokens=color_tokens)),\n",
    "        ('shapes', CollatorForMaskedSelectedTokens(config, processor, tokens=shapes_tokens)),\n",
    "        ('materials', CollatorForMaskedSelectedTokens(config, processor, tokens=materials_tokens)),\n",
    "        ('size', CollatorForMaskedSelectedTokens(config, processor, tokens=size_tokens)),\n",
    "    #     ('relation', CollatorForMaskedSelectedTokens(config, processor, tokens=relation_tokens)),\n",
    "    #     ('identity', IdentityCollator(config, processor)),\n",
    "    ],\n",
    "    'random': [\n",
    "        ('color', CollatorForMaskedRandomSelectedTokens(config, processor, tokens=color_tokens, p=0.2)),\n",
    "        ('shapes', CollatorForMaskedRandomSelectedTokens(config, processor, tokens=shapes_tokens, p=0.2)),\n",
    "        ('materials', CollatorForMaskedRandomSelectedTokens(config, processor, tokens=materials_tokens, p=0.2)),\n",
    "        ('size', CollatorForMaskedRandomSelectedTokens(config, processor, tokens=size_tokens, p=0.2)),\n",
    "    #     ('relation', CollatorForMaskedRandomSelectedTokens(config, processor, tokens=relation_tokens, p=0.2)),\n",
    "    #     ('identity', IdentityCollator(config, processor)),\n",
    "    ]\n",
    "}\n",
    "dlkwargs = {\n",
    "    'batch_size': 512,\n",
    "    'num_workers': int(os.environ.get(\"SLURM_CPUS_PER_TASK\", 4)),\n",
    "    'pin_memory': torch.cuda.is_available(),\n",
    "}\n",
    "\n",
    "all_results = {}\n",
    "for type_, fns_by_category in collate_fns.items():\n",
    "    results = {}\n",
    "    for name, collate_fn in fns_by_category:\n",
    "        train_loader = DataLoader(train_dataset_subset, shuffle=True, collate_fn=collate_fn, **dlkwargs)\n",
    "        test_loader = DataLoader(test_dataset_subset, shuffle=False, collate_fn=collate_fn, **dlkwargs)\n",
    "        systematic_loader = DataLoader(systematic_dataset_subset, shuffle=False, collate_fn=collate_fn, **dlkwargs)\n",
    "        common_systematic_loader = DataLoader(common_systematic_dataset_subset, shuffle=False, collate_fn=collate_fn, **dlkwargs)\n",
    "\n",
    "        test_results = trainer.test(training_model, dataloaders=[test_loader, systematic_loader])\n",
    "        raw_results = trainer.test(training_model, dataloaders=[train_loader, common_systematic_loader])\n",
    "        train_results = [\n",
    "            {k.replace('test_', 'train_'): v for k, v in raw_results[0].items()}]\n",
    "        common_results = [\n",
    "            {k.replace('systematic_test', 'common_systematic_test'): v for k, v in raw_results[1].items()}]\n",
    "        results[name] = test_results + train_results + common_results\n",
    "\n",
    "#     all_results[type_] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594fc7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c3d728",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae1d245",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da526945",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results['config'] = vars(config)\n",
    "all_results['random_baseline'] = random_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0873cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d74cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'outputs/results/{exp_name}.json', 'w') as fp:\n",
    "    json.dump(all_results, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1b6078",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = all_results['selected']\n",
    "categories = results.keys()\n",
    "values1 = [results[cat][0]['test_acc/dataloader_idx_0'] for cat in categories]\n",
    "values2 = [results[cat][1]['systematic_test_acc/dataloader_idx_1'] for cat in categories]\n",
    "values0 = [results[cat][2]['train_acc/dataloader_idx_0'] for cat in categories]\n",
    "valuesR = [random_baseline[cat] for cat in categories]\n",
    "\n",
    "plt.figure(figsize=(9,5))\n",
    "\n",
    "# Define width of bars\n",
    "bar_width = 0.2\n",
    "\n",
    "# Create bars for each category\n",
    "plt.bar([x - 1.5*bar_width for x in range(len(categories))], values0, width=bar_width, label='Train')\n",
    "plt.bar([x - 0.5*bar_width for x in range(len(categories))], values1, width=bar_width, label='Test')\n",
    "plt.bar([x + 0.5*bar_width for x in range(len(categories))], values2, width=bar_width, label='Systematic')\n",
    "plt.bar([x + 1.5*bar_width for x in range(len(categories))], valuesR, width=bar_width, label='Random')\n",
    "\n",
    "xs =  list(range(len(categories)))\n",
    "for i, (v0, v1, v2, vr) in enumerate(zip(values0, values1,values2, valuesR)):\n",
    "    plt.text(xs[i] - 1.5*bar_width, v0 + 0.01, f'{v0:.2f}', ha='center')\n",
    "    plt.text(xs[i] - 0.5*bar_width, v1 + 0.01, f'{v1:.2f}', ha='center')\n",
    "    plt.text(xs[i] + 0.5*bar_width, v2 + 0.01, f'{v2:.2f}', ha='center')\n",
    "    plt.text(xs[i] + 1.5*bar_width, vr + 0.01, f'{vr:.2f}', ha='center')\n",
    "\n",
    "# Add labels and title\n",
    "plt.title(title_exp_name)\n",
    "plt.xlabel('Measure')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0., 1.05)\n",
    "# plt.title('Bar Chart with Two Columns Per Category')\n",
    "plt.xticks(range(len(categories)), categories)\n",
    "plt.legend(framealpha=0.8)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc2446b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = all_results['random']\n",
    "categories = results.keys()\n",
    "values1 = [results[cat][0]['test_acc/dataloader_idx_0'] for cat in categories]\n",
    "values2 = [results[cat][1]['systematic_test_acc/dataloader_idx_1'] for cat in categories]\n",
    "values0 = [results[cat][2]['train_acc/dataloader_idx_0'] for cat in categories]\n",
    "valuesR = [random_baseline[cat] for cat in categories]\n",
    "\n",
    "plt.figure(figsize=(9,5))\n",
    "\n",
    "# Define width of bars\n",
    "bar_width = 0.2\n",
    "\n",
    "# Create bars for each category\n",
    "plt.bar([x - 1.5*bar_width for x in range(len(categories))], values0, width=bar_width, label='Train')\n",
    "plt.bar([x - 0.5*bar_width for x in range(len(categories))], values1, width=bar_width, label='Test')\n",
    "plt.bar([x + 0.5*bar_width for x in range(len(categories))], values2, width=bar_width, label='Systematic')\n",
    "plt.bar([x + 1.5*bar_width for x in range(len(categories))], valuesR, width=bar_width, label='Random')\n",
    "\n",
    "xs =  list(range(len(categories)))\n",
    "for i, (v0, v1, v2, vr) in enumerate(zip(values0, values1,values2, valuesR)):\n",
    "    plt.text(xs[i] - 1.5*bar_width, v0 + 0.01, f'{v0:.2f}', ha='center')\n",
    "    plt.text(xs[i] - 0.5*bar_width, v1 + 0.01, f'{v1:.2f}', ha='center')\n",
    "    plt.text(xs[i] + 0.5*bar_width, v2 + 0.01, f'{v2:.2f}', ha='center')\n",
    "    plt.text(xs[i] + 1.5*bar_width, vr + 0.01, f'{vr:.2f}', ha='center')\n",
    "\n",
    "# Add labels and title\n",
    "plt.title(title_exp_name)\n",
    "plt.xlabel('Measure')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0., 1.05)\n",
    "# plt.title('Bar Chart with Two Columns Per Category')\n",
    "plt.xticks(range(len(categories)), categories)\n",
    "plt.legend()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ad0ca7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2630b490",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20bf6c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a8ab75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13476262",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae804f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3627299",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8441ae22",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 30\n",
    "question = train_dataset.questions[idx]\n",
    "image_idx = question['image_index']\n",
    "scene = train_dataset.indexed_scenes[image_idx]\n",
    "\n",
    "question_str = question['question']\n",
    "answer_str = question['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859aa415",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.rels_to_sample = 0\n",
    "config.only_front_right_relations = False\n",
    "config.filter_symmetric_relations = True\n",
    "config.display_object_properties = False\n",
    "\n",
    "s = Scene.from_dict(scene,\n",
    "                    shuffle_relations=True,\n",
    "                    relations_to_sample=config.rels_to_sample,\n",
    "                    only_front_right=config.only_front_right_relations,\n",
    "                    filter_symmetric=config.filter_symmetric_relations,\n",
    "                    always_display_properties=config.display_object_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4e1b61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c17801",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.rels_to_sample, config.only_front_right_relations, config.filter_symmetric_relations, config.display_object_properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8146c164",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(s.relations), list(enumerate(s.relations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fbbe85",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c78f77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "str(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b68555",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc6f426",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702ed7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "relations_to_sample = 20\n",
    "only_front_right_relations = False\n",
    "filter_symmetric_relations = True\n",
    "display_object_properties = False\n",
    "\n",
    "n_rels = []\n",
    "n_tokens = []\n",
    "for idx in range(len(train_dataset)):\n",
    "    question = train_dataset.questions[idx]\n",
    "\n",
    "    image_idx = question['image_index']\n",
    "    scene = train_dataset.indexed_scenes[image_idx]\n",
    "\n",
    "    question_str = question['question']\n",
    "    answer_str = question['answer']\n",
    "\n",
    "    s = Scene.from_dict(scene,\n",
    "                        shuffle_relations=True,\n",
    "                        relations_to_sample=relations_to_sample,\n",
    "                        only_front_right=only_front_right_relations,\n",
    "                        filter_symmetric=filter_symmetric_relations,\n",
    "                        always_display_properties=display_object_properties)\n",
    "    \n",
    "    n_rels.append(len(s.relations))\n",
    "    n_tokens.append(len(str(s).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6150a7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(min(n_rels), max(n_rels))\n",
    "print(min(n_tokens), max(n_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da05b1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(n_rels, bins=10)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c47ea5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(n_tokens, bins=10)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee4db64",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(n_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e88e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0216c902",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e7b808",
   "metadata": {},
   "outputs": [],
   "source": [
    "only_front_right_relations = False\n",
    "filter_symmetric_relations = True\n",
    "display_object_properties = False\n",
    "\n",
    "n_rels = []\n",
    "n_tokens = []\n",
    "for idx in range(len(train_dataset)):\n",
    "    question = train_dataset.questions[idx]\n",
    "\n",
    "    image_idx = question['image_index']\n",
    "    scene = train_dataset.indexed_scenes[image_idx]\n",
    "\n",
    "    question_str = question['question']\n",
    "    answer_str = question['answer']\n",
    "    \n",
    "    s = Scene.from_dict(scene,\n",
    "                        shuffle_relations=True,\n",
    "                        relations_to_sample=50,\n",
    "                        only_front_right=only_front_right_relations,\n",
    "                        filter_symmetric=filter_symmetric_relations,\n",
    "                        always_display_properties=display_object_properties)\n",
    "    \n",
    "    n_rels.append(len(s.relations))\n",
    "    n_tokens.append(len(str(s).split()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092324ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(min(n_rels), max(n_rels))\n",
    "print(min(n_tokens), max(n_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb872efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(n_rels, bins=10)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17502686",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(n_tokens, bins=10)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8520f7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf923ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "only_front_right_relations = False\n",
    "filter_symmetric_relations = True\n",
    "display_object_properties = True\n",
    "\n",
    "n_rels = []\n",
    "n_tokens = []\n",
    "for idx in range(len(train_dataset)):\n",
    "    question = train_dataset.questions[idx]\n",
    "\n",
    "    image_idx = question['image_index']\n",
    "    scene = train_dataset.indexed_scenes[image_idx]\n",
    "\n",
    "    question_str = question['question']\n",
    "    answer_str = question['answer']\n",
    "\n",
    "    s = Scene.from_dict(scene,\n",
    "                        shuffle_relations=True,\n",
    "                        relations_to_sample=50,\n",
    "                        only_front_right=only_front_right_relations,\n",
    "                        filter_symmetric=filter_symmetric_relations,\n",
    "                        always_display_properties=display_object_properties)\n",
    "    \n",
    "    n_rels.append(len(s.relations))\n",
    "    n_tokens.append(len(str(s).split()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b616d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(min(n_rels), max(n_rels))\n",
    "print(min(n_tokens), max(n_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f7ecc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(n_rels, bins=10)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8d472d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(n_tokens, bins=10)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559d9638",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384dd217",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4bdfe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc2f2dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1475e6e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489ca00e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7eafbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = Path('/mnt/ialabnas/datasets/CLEVR_CoGenT_v1.0')\n",
    "scenes_path = dataset_path / 'scenes/CLEVR_trainA_scenes.json'\n",
    "with scenes_path.open('r') as fp:\n",
    "    scenes = json.load(fp)\n",
    "    \n",
    "questions_path = dataset_path / 'questions/CLEVR_trainA_questions.json'\n",
    "with questions_path.open('r') as fp:\n",
    "    questions = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4346263",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions['questions'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45657d59",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def n_relations(scene):\n",
    "    relations = ['behind', 'front']#, 'left', 'right']\n",
    "    count = 0\n",
    "    relationships = scene['relationships']\n",
    "    for r in relations:\n",
    "        count += sum(map(len, relationships[r]))\n",
    "    return count\n",
    "\n",
    "n_relations(scenes['scenes'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c149062a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(scenes['scenes'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef143a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_relations_per_example = list(map(n_relations, scenes['scenes']))\n",
    "plt.hist(n_relations_per_example)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658ed4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_objects(scene):\n",
    "    return len(scene['objects'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6413840d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_objects_per_example = list(map(n_objects, scenes['scenes']))\n",
    "plt.hist(n_objects_per_example, bins=max(n_objects_per_example)-3)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead396e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b918555",
   "metadata": {},
   "outputs": [],
   "source": [
    "def object_to_text(obj, obj_idx):\n",
    "    properties = ['size', 'color', 'material', 'shape']\n",
    "    obj_str = [f'[O{obj_idx}]'] + [obj[prop] for prop in properties]\n",
    "    return ' '.join(obj_str)\n",
    "\n",
    "def relations_to_text(relations):\n",
    "#     relation_types = ['behind', 'front', 'left', 'right']\n",
    "    relation_types = ['front', 'right'] # symetric relations\n",
    "\n",
    "    relations_str = []\n",
    "    for relation_type in relation_types:\n",
    "        relation = relations[relation_type]\n",
    "        for obj, subjs in enumerate(relation):\n",
    "            relation_str = [f'[O{obj}] {relation_type} [O{subj}]' for subj in subjs]\n",
    "            relations_str.extend(relation_str)\n",
    "    \n",
    "    return relations_str\n",
    "\n",
    "def scene_to_txt(scene, rels_to_sample=None, shuffle=True):\n",
    "    objs_strs = []\n",
    "    for obj_idx, obj in enumerate(scene['objects']):\n",
    "        objs_strs.append(object_to_text(obj, obj_idx=obj_idx))\n",
    "    \n",
    "    relations_strs = relations_to_text(scene['relationships'])\n",
    "    if rels_to_sample and rels_to_sample < len(relations_strs):\n",
    "        relations_strs = random.sample(relations_strs, k)\n",
    "    if shuffle:\n",
    "        random.shuffle(relations_strs)\n",
    "\n",
    "    return ' [SEP] '.join(objs_strs + relations_strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3acc5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "ip = '/mnt/ialabnas/datasets/CLEVR_CoGenT_v1.0/images/trainA/' + questions['questions'][8888]['image_filename']\n",
    "Image.open(ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33315679",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_to_text(scenes['scenes'][8888]['objects'][0], obj_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae611da",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_to_text(scenes['scenes'][8888]['objects'][1], obj_idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645397ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "relations_to_text(scenes['scenes'][8888]['relationships'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1f83d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_to_txt(scenes['scenes'][8888])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e241e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scene_to_txt(scenes['scenes'][8888], rels_to_sample=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917e20f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c36bb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_str = lambda s: str(Scene.from_dict(s, \n",
    "                                        relations_to_sample=config.rels_to_sample,\n",
    "                                        only_front_right=config.only_front_right_relations,\n",
    "                                        filter_symmetric=config.filter_symmetric_relations,\n",
    "                                        always_display_properties=config.display_object_properties))\n",
    "\n",
    "str_len_per_example = list(map(len, map(str.split, map(to_str, scenes['scenes']))))\n",
    "plt.hist(str_len_per_example)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd81824d",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_fnc = lambda s: str(Scene.from_dict(s, relations_to_sample=50,\n",
    "                                        only_front_right=config.only_front_right_relations,\n",
    "                                        filter_symmetric=config.filter_symmetric_relations,\n",
    "                                        always_display_properties=config.display_object_properties))\n",
    "\n",
    "str_len_per_example = list(map(len, map(str.split, map(str_fnc, scenes['scenes']))))\n",
    "plt.hist(str_len_per_example)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e96374",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f888d4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = set()\n",
    "for scene in scenes['scenes']:\n",
    "    scene_text = scene_to_txt(scene)\n",
    "    vocabulary.update(scene_text.split())\n",
    "\n",
    "vocabulary = ['[CLS]', '[PAD]'] + list(sorted(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bf1900",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vocabulary), vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f493b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ffc2483",
   "metadata": {},
   "source": [
    "## All Possible Colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693dc9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_possible_colors = set()\n",
    "for n_colors in ['8c', '27c', '64c', '125c', '216c']:\n",
    "    vocab_path = f'/workspace1/fidelrio/CLEVR_CoGenT_v1.0/colored-v2/{n_colors}/vocab.txt'\n",
    "    with open(vocab_path) as fp:\n",
    "        vocab = list(map(str.strip, fp.readlines()))\n",
    "        color_vocab = [w for w in vocab if w.startswith('#')]\n",
    "        all_possible_colors.update(color_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3d4052",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_possible_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa27e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "print('\\n'.join(textwrap.wrap(', '.join([f\"'{w}'\" for w in all_possible_colors]), width=103)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8952790e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
